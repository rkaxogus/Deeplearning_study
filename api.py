from fastapi import FastAPI, File, UploadFile, Form
from PIL import Image
import torch
import torchvision.transforms as transforms
import torchvision.models as models
import zipfile
import tempfile
import os
import json

# FastAPI ì•± ìƒì„±
app = FastAPI()

# GPU ë˜ëŠ” CPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model_path = "C:/Users/user/OneDrive/Desktop/Resnet18-real/modelnew/resnet18-3.pth"
state_dict = torch.load(model_path, map_location=device)

# ëª¨ë¸ì˜ ì¶œë ¥ì¸µ í¬ê¸° í™•ì¸
num_classes = state_dict['fc.weight'].shape[0]

# ëª¨ë¸ ì •ì˜ ë° ê°€ì¤‘ì¹˜ ë¡œë“œ
model = models.resnet18(pretrained=False)
model.fc = torch.nn.Linear(512, num_classes)
model.load_state_dict(state_dict)
model.to(device)
model.eval()

# ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# âœ… ZIP íŒŒì¼ ì—…ë¡œë“œ + ì •ë‹µ ë ˆì´ë¸” ê²€ì¦ API (ì´ëª¨í‹°ì½˜ ë° ê°„ê²°í•œ ì¶œë ¥)
@app.post("/predict_tent/")
async def evaluate_model(file: UploadFile = File(...), labels: str = Form(...)):
    """
    ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ì •ë‹µ ë ˆì´ë¸”ì„ ë¹„êµí•˜ì—¬ ëª¨ë¸ ì •í™•ë„ë¥¼ í‰ê°€í•˜ëŠ” API.
    
    :param file: ì—…ë¡œë“œëœ ZIP íŒŒì¼ (ì´ë¯¸ì§€ íŒŒì¼ í¬í•¨)
    :param labels: JSON í˜•ì‹ì˜ ì •ë‹µ ë ˆì´ë¸” (ì˜ˆ: '{"image1.jpg": 3, "image2.jpg": 7}')
    :return: ê°„ëµí•œ ì´ë¯¸ì§€ë³„ ê²°ê³¼ì™€ ì „ì²´ ì •ë‹µ ê°œìˆ˜ ë° ì •í™•ë„
    """
    results = []
    correct_count = 0  # ë§ì¶˜ ì´ë¯¸ì§€ ê°œìˆ˜
    total_count = 0    # ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜

    # JSON í˜•íƒœì˜ ì •ë‹µ ë ˆì´ë¸” íŒŒì‹± (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)
    try:
        true_labels = json.loads(labels)
    except json.JSONDecodeError:
        return {"error": "ì •ë‹µ ë ˆì´ë¸”ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤."}

    # ì„ì‹œ í´ë” ìƒì„± í›„ ZIP íŒŒì¼ ì €ì¥ ë° ì••ì¶• í•´ì œ
    with tempfile.TemporaryDirectory() as temp_dir:
        zip_path = os.path.join(temp_dir, "uploaded.zip")
        with open(zip_path, "wb") as buffer:
            buffer.write(await file.read())

        with zipfile.ZipFile(zip_path, "r") as zip_ref:
            zip_ref.extractall(temp_dir)

        # ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨í•˜ì—¬ ì´ë¯¸ì§€ íŒŒì¼ ê²€ìƒ‰
        for root, dirs, files in os.walk(temp_dir):
            for img_name in files:
                if img_name.lower().endswith(("png", "jpg", "jpeg")):
                    img_path = os.path.join(root, img_name)
                    try:
                        image = Image.open(img_path).convert("RGB")
                    except Exception:
                        continue

                    image = transform(image).unsqueeze(0).to(device)
                    with torch.no_grad():
                        output = model(image)
                        predicted_class = torch.argmax(output, 1).item()

                    true_class = true_labels.get(img_name, -1)
                    is_correct = (predicted_class == true_class)
                    emoji = "âœ…" if is_correct else "âŒ"
                    if is_correct:
                        correct_count += 1
                    total_count += 1

                    # í•œ ì¤„ë¡œ ê°„ë‹¨í•˜ê²Œ ê²°ê³¼ í‘œí˜„ (ğŸ“„: ì´ë¯¸ì§€, âœ…/âŒ: ì •ë‹µ ì—¬ë¶€)
                    results.append(f"ğŸ“„ {img_name} : {emoji} (ì˜ˆì¸¡: {predicted_class}, ì •ë‹µ: {true_class if true_class != -1 else 'N/A'})")

    # ì „ì²´ ì •í™•ë„ ë° ì •ë‹µ ê°œìˆ˜ ê³„ì‚°
    accuracy = round((correct_count / total_count) * 100, 2) if total_count > 0 else 0.0
    summary = f"ì •ë‹µ: {correct_count}/{total_count} (ì •í™•ë„: {accuracy}%)"

    return {
        "summary": summary,
        "results": results
    }

# FastAPI ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

#http://127.0.0.1:8000/docs