{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš© ì¤‘ì¸ GPU: Quadro RTX 4000\n",
      "\n",
      "ğŸ“¢ Training Started! Logging Every Epoch:\n",
      "\n",
      "\n",
      "ğŸ“¢ Epoch [1/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.7751 | ğŸ“‰ Train Loss: 0.7066 | ğŸ¯ Valid Accuracy: 0.8609 | ğŸ“‰ Valid Loss: 0.4043\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 1, Accuracy: 0.8609)\n",
      "\n",
      "ğŸ“¢ Epoch [2/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.8984 | ğŸ“‰ Train Loss: 0.3202 | ğŸ¯ Valid Accuracy: 0.8455 | ğŸ“‰ Valid Loss: 0.5641\n",
      "\n",
      "ğŸ“¢ Epoch [3/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9305 | ğŸ“‰ Train Loss: 0.2186 | ğŸ¯ Valid Accuracy: 0.8808 | ğŸ“‰ Valid Loss: 0.4280\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 3, Accuracy: 0.8808)\n",
      "\n",
      "ğŸ“¢ Epoch [4/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9450 | ğŸ“‰ Train Loss: 0.1698 | ğŸ¯ Valid Accuracy: 0.8661 | ğŸ“‰ Valid Loss: 0.5247\n",
      "\n",
      "ğŸ“¢ Epoch [5/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9513 | ğŸ“‰ Train Loss: 0.1520 | ğŸ¯ Valid Accuracy: 0.9014 | ğŸ“‰ Valid Loss: 0.3233\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 5, Accuracy: 0.9014)\n",
      "\n",
      "ğŸ“¢ Epoch [6/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9628 | ğŸ“‰ Train Loss: 0.1133 | ğŸ¯ Valid Accuracy: 0.8845 | ğŸ“‰ Valid Loss: 0.4239\n",
      "\n",
      "ğŸ“¢ Epoch [7/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9626 | ğŸ“‰ Train Loss: 0.1136 | ğŸ¯ Valid Accuracy: 0.8911 | ğŸ“‰ Valid Loss: 0.4234\n",
      "\n",
      "ğŸ“¢ Epoch [8/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9620 | ğŸ“‰ Train Loss: 0.1173 | ğŸ¯ Valid Accuracy: 0.8962 | ğŸ“‰ Valid Loss: 0.4457\n",
      "\n",
      "ğŸ“¢ Epoch [9/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9666 | ğŸ“‰ Train Loss: 0.0913 | ğŸ¯ Valid Accuracy: 0.8852 | ğŸ“‰ Valid Loss: 0.5048\n",
      "\n",
      "ğŸ“¢ Epoch [10/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9696 | ğŸ“‰ Train Loss: 0.0947 | ğŸ¯ Valid Accuracy: 0.8896 | ğŸ“‰ Valid Loss: 0.4105\n",
      "\n",
      "ğŸ“¢ Epoch [11/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9763 | ğŸ“‰ Train Loss: 0.0753 | ğŸ¯ Valid Accuracy: 0.9139 | ğŸ“‰ Valid Loss: 0.3728\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 11, Accuracy: 0.9139)\n",
      "\n",
      "ğŸ“¢ Epoch [12/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9834 | ğŸ“‰ Train Loss: 0.0493 | ğŸ¯ Valid Accuracy: 0.8793 | ğŸ“‰ Valid Loss: 0.5159\n",
      "\n",
      "ğŸ“¢ Epoch [13/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9746 | ğŸ“‰ Train Loss: 0.0721 | ğŸ¯ Valid Accuracy: 0.8977 | ğŸ“‰ Valid Loss: 0.4785\n",
      "\n",
      "ğŸ“¢ Epoch [14/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9748 | ğŸ“‰ Train Loss: 0.0721 | ğŸ¯ Valid Accuracy: 0.9110 | ğŸ“‰ Valid Loss: 0.3962\n",
      "\n",
      "ğŸ“¢ Epoch [15/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9847 | ğŸ“‰ Train Loss: 0.0464 | ğŸ¯ Valid Accuracy: 0.9065 | ğŸ“‰ Valid Loss: 0.4137\n",
      "\n",
      "ğŸ“¢ Epoch [16/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9765 | ğŸ“‰ Train Loss: 0.0806 | ğŸ¯ Valid Accuracy: 0.9014 | ğŸ“‰ Valid Loss: 0.3695\n",
      "\n",
      "ğŸ“¢ Epoch [17/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9861 | ğŸ“‰ Train Loss: 0.0429 | ğŸ¯ Valid Accuracy: 0.9132 | ğŸ“‰ Valid Loss: 0.3630\n",
      "\n",
      "ğŸ“¢ Epoch [18/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9859 | ğŸ“‰ Train Loss: 0.0391 | ğŸ¯ Valid Accuracy: 0.8985 | ğŸ“‰ Valid Loss: 0.4498\n",
      "\n",
      "ğŸ“¢ Epoch [19/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9780 | ğŸ“‰ Train Loss: 0.0691 | ğŸ¯ Valid Accuracy: 0.8882 | ğŸ“‰ Valid Loss: 0.5128\n",
      "\n",
      "ğŸ“¢ Epoch [20/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9773 | ğŸ“‰ Train Loss: 0.0781 | ğŸ¯ Valid Accuracy: 0.8999 | ğŸ“‰ Valid Loss: 0.3616\n",
      "\n",
      "ğŸ“¢ Epoch [21/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9845 | ğŸ“‰ Train Loss: 0.0498 | ğŸ¯ Valid Accuracy: 0.8918 | ğŸ“‰ Valid Loss: 0.4714\n",
      "\n",
      "ğŸ“¢ Epoch [22/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9843 | ğŸ“‰ Train Loss: 0.0509 | ğŸ¯ Valid Accuracy: 0.8933 | ğŸ“‰ Valid Loss: 0.4846\n",
      "\n",
      "ğŸ“¢ Epoch [23/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9801 | ğŸ“‰ Train Loss: 0.0636 | ğŸ¯ Valid Accuracy: 0.8926 | ğŸ“‰ Valid Loss: 0.4459\n",
      "\n",
      "ğŸ“¢ Epoch [24/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9828 | ğŸ“‰ Train Loss: 0.0519 | ğŸ¯ Valid Accuracy: 0.9117 | ğŸ“‰ Valid Loss: 0.3662\n",
      "\n",
      "ğŸ“¢ Epoch [25/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9859 | ğŸ“‰ Train Loss: 0.0456 | ğŸ¯ Valid Accuracy: 0.8985 | ğŸ“‰ Valid Loss: 0.5230\n",
      "\n",
      "ğŸ“¢ Epoch [26/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9849 | ğŸ“‰ Train Loss: 0.0521 | ğŸ¯ Valid Accuracy: 0.9065 | ğŸ“‰ Valid Loss: 0.4119\n",
      "\n",
      "ğŸ“¢ Epoch [27/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9891 | ğŸ“‰ Train Loss: 0.0338 | ğŸ¯ Valid Accuracy: 0.9169 | ğŸ“‰ Valid Loss: 0.3898\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 27, Accuracy: 0.9169)\n",
      "\n",
      "ğŸ“¢ Epoch [28/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9891 | ğŸ“‰ Train Loss: 0.0303 | ğŸ¯ Valid Accuracy: 0.8970 | ğŸ“‰ Valid Loss: 0.5228\n",
      "\n",
      "ğŸ“¢ Epoch [29/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9895 | ğŸ“‰ Train Loss: 0.0318 | ğŸ¯ Valid Accuracy: 0.9058 | ğŸ“‰ Valid Loss: 0.4888\n",
      "\n",
      "ğŸ“¢ Epoch [30/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9866 | ğŸ“‰ Train Loss: 0.0371 | ğŸ¯ Valid Accuracy: 0.9021 | ğŸ“‰ Valid Loss: 0.4739\n",
      "ğŸ“„ í•™ìŠµ ê²°ê³¼ CSV ì €ì¥ë¨: C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\\ëª¨ë¸1new.csv\n",
      "âœ… í•™ìŠµ ì¢…ë£Œ! ìµœê³  ì„±ëŠ¥ì„ ê¸°ë¡í•œ Epoch: 27, ğŸ¯ Train Accuracy: 0.9891, ğŸ“‰ Train Loss: 0.0338, ğŸ¯ Valid Accuracy: 0.9169, ğŸ“‰ Valid Loss: 0.3898\n"
     ]
    }
   ],
   "source": [
    "#model1new.pth\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "import random\n",
    "\n",
    "# âœ… GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ… ì‚¬ìš© ì¤‘ì¸ GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# âœ… ê²½ë¡œ ì„¤ì •\n",
    "data_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/data/category_data3\"\n",
    "model_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/model\"\n",
    "csv_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\"\n",
    "json_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/jsonnew\"  # âœ… JSON ì €ì¥ ê²½ë¡œ\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "os.makedirs(json_dir, exist_ok=True)  # âœ… JSON ì €ì¥ í´ë” ìƒì„±\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë¶„í•  ì¸ë±ìŠ¤ ì €ì¥ ê²½ë¡œ\n",
    "train_indices_path = os.path.join(json_dir, \"model1newtrain.json\")\n",
    "val_indices_path = os.path.join(json_dir, \"model1newval.json\")\n",
    "test_indices_path = os.path.join(json_dir, \"model1newtest.json\")\n",
    "\n",
    "# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# âœ… ë°ì´í„° ì „ì²˜ë¦¬\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# âœ… ê° í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ë¶„ë°°\n",
    "class_indices = {cls: [] for cls in dataset.class_to_idx.values()}\n",
    "\n",
    "for idx, (path, label) in enumerate(dataset.samples):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# âœ… ê° í´ë˜ìŠ¤ë³„ë¡œ 7:2:1 ë¹„ìœ¨ë¡œ ë¶„í•  (í•™ìŠµ:ê²€ì¦:í…ŒìŠ¤íŠ¸)\n",
    "train_indices, val_indices, test_indices = [], [], []\n",
    "\n",
    "for indices in class_indices.values():\n",
    "    random.shuffle(indices)  # ëœë¤ ì…”í”Œ\n",
    "    num_total = len(indices)\n",
    "    num_train = int(num_total * 0.7)\n",
    "    num_val = int(num_total * 0.2)\n",
    "    num_test = num_total - num_train - num_val\n",
    "\n",
    "    train_indices.extend(indices[:num_train])\n",
    "    val_indices.extend(indices[num_train:num_train+num_val])\n",
    "    test_indices.extend(indices[num_train+num_val:])\n",
    "\n",
    "# âœ… ë¶„í• ëœ ì¸ë±ìŠ¤ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "with open(train_indices_path, \"w\") as f:\n",
    "    json.dump(train_indices, f)\n",
    "with open(val_indices_path, \"w\") as f:\n",
    "    json.dump(val_indices, f)\n",
    "with open(test_indices_path, \"w\") as f:\n",
    "    json.dump(test_indices, f)\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë¶„í• \n",
    "dataset_train = Subset(dataset, train_indices)\n",
    "dataset_val = Subset(dataset, val_indices)\n",
    "dataset_test = Subset(dataset, test_indices)\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë” ì„¤ì •\n",
    "test_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# âœ… EfficientNet-B0 ëª¨ë¸ ì •ì˜\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(dataset.classes))\n",
    "model.to(device)\n",
    "\n",
    "# âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# âœ… í•™ìŠµ ë£¨í”„\n",
    "best_valid_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "csv_path = os.path.join(csv_dir, \"ëª¨ë¸1 new í•™ìŠµê¸°ë¡.csv\")\n",
    "train_losses, valid_losses, train_accuracies, valid_accuracies = [], [], [], []\n",
    "\n",
    "print(\"\\nğŸ“¢ Training Started! Logging Every Epoch:\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nğŸ“¢ Epoch [{epoch+1}/{EPOCHS}] ì‹œì‘\")\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss /= total_train\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # âœ… ê²€ì¦ ë‹¨ê³„\n",
    "    model.eval()\n",
    "    valid_loss, valid_correct = 0, 0\n",
    "    total_valid = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "            valid_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_valid += labels.size(0)\n",
    "\n",
    "    valid_loss /= total_valid\n",
    "    valid_accuracy = valid_correct / total_valid\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "# âœ… ìµœê³ ì˜ ê²€ì¦ ì •í™•ë„ë¥¼ ê¸°ë¡í•œ ì—í¬í¬ ëª¨ë¸ ì €ì¥\n",
    "    print(f\"   ğŸ¯ Train Accuracy: {train_accuracy:.4f} | ğŸ“‰ Train Loss: {train_loss:.4f} | \"\n",
    "        f\"ğŸ¯ Valid Accuracy: {valid_accuracy:.4f} | ğŸ“‰ Valid Loss: {valid_loss:.4f}\")\n",
    "\n",
    "    if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "        best_epoch = epoch + 1\n",
    "        best_model_path = os.path.join(model_dir, \"model1new.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch {epoch+1}, Accuracy: {best_valid_accuracy:.4f})\")\n",
    "\n",
    "# âœ… ê²°ê³¼ CSV ì €ì¥\n",
    "df = pd.DataFrame({\n",
    "    'Epoch': range(1, len(train_losses) + 1),\n",
    "    'Train Loss': train_losses,\n",
    "    'Valid Loss': valid_losses,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Valid Accuracy': valid_accuracies\n",
    "})\n",
    "csv_path = os.path.join(csv_dir, \"ëª¨ë¸1new.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"ğŸ“„ í•™ìŠµ ê²°ê³¼ CSV ì €ì¥ë¨: {csv_path}\")\n",
    "\n",
    "# âœ… ê²€ì¦ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ì—í¬í¬ì˜ ëª¨ë“  ì •ë³´ ì¶œë ¥\n",
    "print(f\"âœ… í•™ìŠµ ì¢…ë£Œ! ìµœê³  ì„±ëŠ¥ì„ ê¸°ë¡í•œ Epoch: {best_epoch}, ğŸ¯ Train Accuracy: {train_accuracies[best_epoch-1]:.4f}, ğŸ“‰ Train Loss: {train_losses[best_epoch-1]:.4f}, ğŸ¯ Valid Accuracy: {best_valid_accuracy:.4f}, ğŸ“‰ Valid Loss: {valid_losses[best_epoch-1]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
