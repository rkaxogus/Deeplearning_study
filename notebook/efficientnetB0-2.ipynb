{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 10개의 클래스 발견: ['가방·박스·웨건', '공구·액세서리', '냉·난방용품', '랜턴', '매트·침낭', '식기·주방', '전기·전자기기', '테이블·체어', '텐트·타프', '화로대·버너']\n",
      "✅ 총 13883개의 이미지 로드 완료\n",
      "\n",
      "=== Starting Epoch 1/30 ===\n",
      "Epoch 1/30: 100% completed\n",
      "Epoch 1/30 completed.\n",
      "Train Loss: 0.7227, Train Acc: 0.7688, Valid Loss: 0.5106, Valid Acc: 0.8408\n",
      "Created directory: ./models\n",
      "Model saved to ./models/category_model3.pth\n",
      "\n",
      "=== Starting Epoch 2/30 ===\n",
      "Epoch 2/30: 100% completed\n",
      "Epoch 2/30 completed.\n",
      "Train Loss: 0.2600, Train Acc: 0.9158, Valid Loss: 0.4078, Valid Acc: 0.8725\n",
      "Model saved to ./models/category_model3.pth\n",
      "\n",
      "=== Starting Epoch 3/30 ===\n",
      "Epoch 3/30: 100% completed\n",
      "Epoch 3/30 completed.\n",
      "Train Loss: 0.1537, Train Acc: 0.9504, Valid Loss: 0.4542, Valid Acc: 0.8740\n",
      "Model saved to ./models/category_model3.pth\n",
      "\n",
      "=== Starting Epoch 4/30 ===\n",
      "Epoch 4/30: 100% completed\n",
      "Epoch 4/30 completed.\n",
      "Train Loss: 0.1312, Train Acc: 0.9591, Valid Loss: 0.5093, Valid Acc: 0.8596\n",
      "\n",
      "=== Starting Epoch 5/30 ===\n",
      "Epoch 5/30: 100% completed\n",
      "Epoch 5/30 completed.\n",
      "Train Loss: 0.1127, Train Acc: 0.9655, Valid Loss: 0.5065, Valid Acc: 0.8704\n",
      "\n",
      "=== Starting Epoch 6/30 ===\n",
      "Epoch 6/30: 100% completed\n",
      "Epoch 6/30 completed.\n",
      "Train Loss: 0.0925, Train Acc: 0.9694, Valid Loss: 0.5188, Valid Acc: 0.8711\n",
      "\n",
      "=== Starting Epoch 7/30 ===\n",
      "Epoch 7/30: 100% completed\n",
      "Epoch 7/30 completed.\n",
      "Train Loss: 0.0765, Train Acc: 0.9751, Valid Loss: 0.5282, Valid Acc: 0.8754\n",
      "Model saved to ./models/category_model3.pth\n",
      "\n",
      "=== Starting Epoch 8/30 ===\n",
      "Epoch 8/30: 100% completed\n",
      "Epoch 8/30 completed.\n",
      "Train Loss: 0.0622, Train Acc: 0.9813, Valid Loss: 0.4524, Valid Acc: 0.8902\n",
      "Model saved to ./models/category_model3.pth\n",
      "\n",
      "=== Starting Epoch 9/30 ===\n",
      "Epoch 9/30: 100% completed\n",
      "Epoch 9/30 completed.\n",
      "Train Loss: 0.0565, Train Acc: 0.9814, Valid Loss: 0.4730, Valid Acc: 0.8894\n",
      "\n",
      "=== Starting Epoch 10/30 ===\n",
      "Epoch 10/30: 100% completed\n",
      "Epoch 10/30 completed.\n",
      "Train Loss: 0.0658, Train Acc: 0.9796, Valid Loss: 0.5189, Valid Acc: 0.8840\n",
      "\n",
      "=== Starting Epoch 11/30 ===\n",
      "Epoch 11/30: 100% completed\n",
      "Epoch 11/30 completed.\n",
      "Train Loss: 0.0602, Train Acc: 0.9806, Valid Loss: 0.5036, Valid Acc: 0.8804\n",
      "\n",
      "=== Starting Epoch 12/30 ===\n",
      "Epoch 12/30: 100% completed\n",
      "Epoch 12/30 completed.\n",
      "Train Loss: 0.0392, Train Acc: 0.9869, Valid Loss: 0.5120, Valid Acc: 0.8822\n",
      "\n",
      "=== Starting Epoch 13/30 ===\n",
      "Epoch 13/30: 100% completed\n",
      "Epoch 13/30 completed.\n",
      "Train Loss: 0.0377, Train Acc: 0.9886, Valid Loss: 0.5193, Valid Acc: 0.8855\n",
      "\n",
      "=== Starting Epoch 14/30 ===\n",
      "Epoch 14/30: 100% completed\n",
      "Epoch 14/30 completed.\n",
      "Train Loss: 0.0588, Train Acc: 0.9815, Valid Loss: 0.6258, Valid Acc: 0.8686\n",
      "\n",
      "=== Starting Epoch 15/30 ===\n",
      "Epoch 15/30: 100% completed\n",
      "Epoch 15/30 completed.\n",
      "Train Loss: 0.0518, Train Acc: 0.9838, Valid Loss: 0.5672, Valid Acc: 0.8758\n",
      "\n",
      "=== Starting Epoch 16/30 ===\n",
      "Epoch 16/30: 100% completed\n",
      "Epoch 16/30 completed.\n",
      "Train Loss: 0.0530, Train Acc: 0.9834, Valid Loss: 0.5553, Valid Acc: 0.8797\n",
      "\n",
      "=== Starting Epoch 17/30 ===\n",
      "Epoch 17/30: 100% completed\n",
      "Epoch 17/30 completed.\n",
      "Train Loss: 0.0404, Train Acc: 0.9866, Valid Loss: 0.5394, Valid Acc: 0.8707\n",
      "\n",
      "=== Starting Epoch 18/30 ===\n",
      "Epoch 18/30: 100% completed\n",
      "Epoch 18/30 completed.\n",
      "Train Loss: 0.0312, Train Acc: 0.9892, Valid Loss: 0.5420, Valid Acc: 0.8830\n",
      "\n",
      "=== Starting Epoch 19/30 ===\n",
      "Epoch 19/30: 100% completed\n",
      "Epoch 19/30 completed.\n",
      "Train Loss: 0.0236, Train Acc: 0.9926, Valid Loss: 0.5895, Valid Acc: 0.8783\n",
      "\n",
      "=== Starting Epoch 20/30 ===\n",
      "Epoch 20/30: 100% completed\n",
      "Epoch 20/30 completed.\n",
      "Train Loss: 0.0254, Train Acc: 0.9914, Valid Loss: 0.5949, Valid Acc: 0.8714\n",
      "\n",
      "=== Starting Epoch 21/30 ===\n",
      "Epoch 21/30: 100% completed\n",
      "Epoch 21/30 completed.\n",
      "Train Loss: 0.0319, Train Acc: 0.9893, Valid Loss: 0.5792, Valid Acc: 0.8902\n",
      "\n",
      "=== Starting Epoch 22/30 ===\n",
      "Epoch 22/30: 100% completed\n",
      "Epoch 22/30 completed.\n",
      "Train Loss: 0.0468, Train Acc: 0.9847, Valid Loss: 0.6760, Valid Acc: 0.8581\n",
      "\n",
      "=== Starting Epoch 23/30 ===\n",
      "Epoch 23/30: 100% completed\n",
      "Epoch 23/30 completed.\n",
      "Train Loss: 0.0394, Train Acc: 0.9876, Valid Loss: 0.6370, Valid Acc: 0.8736\n",
      "\n",
      "=== Starting Epoch 24/30 ===\n",
      "Epoch 24/30: 97% completed\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 177\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 177\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 63\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     61\u001b[0m train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     64\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\classification\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\classification\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\classification\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\classification\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\classification\\lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[2], line 148\u001b[0m, in \u001b[0;36mCustomCategoryDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# ✅ 이미지 파일이 정상적으로 열리는지 확인\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🚨 오류: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 열 수 없음 (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\classification\\lib\\site-packages\\PIL\\Image.py:993\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    991\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m--> 993\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\classification\\lib\\site-packages\\PIL\\ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.amp import GradScaler, autocast\n",
    "from PIL import Image\n",
    "\n",
    "def main():\n",
    "    # 데이터 경로 설정 (최상위 폴더)\n",
    "    data_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\data\\category_data\"\n",
    "    \n",
    "    # 모델 저장 경로 (상대 경로)\n",
    "    model_save_path = \"./models/category_model3.pth\"\n",
    "\n",
    "    # 하이퍼파라미터\n",
    "    BATCH_SIZE = 128\n",
    "    IMG_SIZE = (224, 224)\n",
    "    EPOCHS = 30\n",
    "    LEARNING_RATE = 0.001\n",
    "    NUM_CLASSES = 10  # 클래스 개수 (자동 탐색)\n",
    "\n",
    "    # 데이터 전처리\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # ✅ 데이터셋 로드 (하위 폴더 내 이미지 자동 탐색)\n",
    "    dataset = CustomCategoryDataset(data_dir, transform=transform)\n",
    "    NUM_CLASSES = len(dataset.classes)  # 클래스 개수 자동 설정\n",
    "\n",
    "    # ✅ 데이터 분할 (80% 훈련, 20% 검증)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    valid_size = len(dataset) - train_size\n",
    "    train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # ✅ EfficientNet-B0 모델 정의\n",
    "    model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # ✅ 손실 함수 및 옵티마이저\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scaler = GradScaler(\"cuda\")\n",
    "\n",
    "    # ✅ 검증 정확도가 가장 높았던 모델 저장\n",
    "    best_valid_accuracy = 0.0\n",
    "\n",
    "    # ✅ 학습 루프\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n=== Starting Epoch {epoch + 1}/{EPOCHS} ===\")\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "            progress = int((batch_idx + 1) / len(train_loader) * 100)\n",
    "            print(f\"Epoch {epoch + 1}/{EPOCHS}: {progress}% completed\", end=\"\\r\")\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_accuracy = train_correct / len(train_loader.dataset)\n",
    "\n",
    "        # ✅ Validation 루프\n",
    "        valid_loss, valid_correct = 0, 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "                valid_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = valid_correct / len(valid_loader.dataset)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS} completed.\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
    "            f\"Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_accuracy:.4f}\")\n",
    "\n",
    "        # ✅ 모델 저장 (최고 정확도 업데이트 시)\n",
    "        if valid_accuracy > best_valid_accuracy:\n",
    "            best_valid_accuracy = valid_accuracy\n",
    "            save_model(model, optimizer, epoch + 1, train_loss, valid_loss, train_accuracy, valid_accuracy, model_save_path)\n",
    "\n",
    "    print(\"\\nTraining completed. Best model saved to:\", model_save_path)\n",
    "\n",
    "# ✅ CustomCategoryDataset에서 데이터 로드 상태 출력 추가\n",
    "class CustomCategoryDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # ✅ 클래스 목록 가져오기 (최상위 폴더만)\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "\n",
    "        print(f\"✅ 총 {len(self.classes)}개의 클래스 발견: {self.classes}\")  # 디버깅 출력\n",
    "\n",
    "        # ✅ 하위 폴더 내 이미지 자동 탐색\n",
    "        for cls_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, cls_name)\n",
    "            found_images = 0\n",
    "            for root, _, files in os.walk(class_dir):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif', 'tiff', 'webp')):\n",
    "                        self.image_paths.append(os.path.join(root, file))\n",
    "                        self.labels.append(self.class_to_idx[cls_name])\n",
    "                        found_images += 1\n",
    "\n",
    "            if found_images == 0:\n",
    "                print(f\"⚠️ {cls_name} 폴더 내 이미지가 없음 (데이터셋 문제 가능)\")\n",
    "\n",
    "        print(f\"✅ 총 {len(self.image_paths)}개의 이미지 로드 완료\")  # 디버깅 출력\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # ✅ 이미지 파일이 정상적으로 열리는지 확인\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"🚨 오류: {img_path} 열 수 없음 ({e})\")\n",
    "            return None, None  # 데이터 로드 실패 시 None 반환\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def save_model(model, optimizer, epoch, train_loss, valid_loss, train_accuracy, valid_accuracy, model_save_path):\n",
    "    \"\"\"모델을 저장하는 함수\"\"\"\n",
    "    model_dir = os.path.dirname(model_save_path)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "        print(f\"Created directory: {model_dir}\")\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'valid_loss': valid_loss,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'valid_accuracy': valid_accuracy,\n",
    "    }, model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 사용 중인 GPU: Quadro RTX 4000\n",
      "\n",
      "🔥 검증 데이터셋에서 문제있는 데이터 찾기 🔥\n",
      "\n",
      "✅ 검증 데이터셋에서 자주 틀린 클래스 (상위 10개)\n",
      "Class 식기·주방: 23번 오답 발생\n",
      "Class 화로대·버너: 18번 오답 발생\n",
      "Class 매트·침낭: 16번 오답 발생\n",
      "Class 냉·난방용품: 16번 오답 발생\n",
      "Class 가방·박스·웨건: 14번 오답 발생\n",
      "Class 테이블·체어: 11번 오답 발생\n",
      "Class 전기·전자기기: 10번 오답 발생\n",
      "Class 공구·액세서리: 6번 오답 발생\n",
      "Class 텐트·타프: 4번 오답 발생\n",
      "Class 랜턴: 4번 오답 발생\n",
      "\n",
      "✅ 검증 데이터셋 클래스별 정확도:\n",
      "Class 가방·박스·웨건: 95.10% 정확도\n",
      "Class 공구·액세서리: 95.20% 정확도\n",
      "Class 냉·난방용품: 95.35% 정확도\n",
      "Class 랜턴: 95.56% 정확도\n",
      "Class 매트·침낭: 96.99% 정확도\n",
      "Class 식기·주방: 94.38% 정확도\n",
      "Class 전기·전자기기: 96.34% 정확도\n",
      "Class 테이블·체어: 95.15% 정확도\n",
      "Class 텐트·타프: 98.17% 정확도\n",
      "Class 화로대·버너: 93.38% 정확도\n",
      "\n",
      "✅ 검증 데이터셋에서 확신도가 낮은 샘플 (상위 10개)\n",
      "\n",
      "📄 검증 데이터셋에서 오답이 많은 샘플 저장됨: C:/Users/user/OneDrive/Desktop/Resnet18-real/csv\\misclassified_samples.csv\n",
      "📄 검증 데이터셋에서 확신도가 낮은 샘플 저장됨: C:/Users/user/OneDrive/Desktop/Resnet18-real/csv\\low_confidence_samples.csv\n",
      "📄 클래스별 정확도 저장됨: C:/Users/user/OneDrive/Desktop/Resnet18-real/csv\\classwise_accuracy.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "# ✅ 모델 및 데이터 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"✅ 사용 중인 GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# ✅ 모델 및 데이터셋 설정\n",
    "data_dir = \"C:/Users/user/OneDrive/Desktop/Resnet18-real/data/category_data\"\n",
    "model_path = \"C:/Users/user/OneDrive/Desktop/Resnet18-real/model/best_category_model.pth\"\n",
    "csv_dir = \"C:/Users/user/OneDrive/Desktop/Resnet18-real/csv\"\n",
    "\n",
    "# ✅ 데이터셋 로드\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "valid_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - valid_size\n",
    "_, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size])\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ✅ 모델 불러오기\n",
    "model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(dataset.classes))\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ✅ 검증 데이터셋에서 자주 틀린 데이터 찾기\n",
    "def find_misclassified_samples(loader):\n",
    "    misclassified = []\n",
    "    class_misclassification = Counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.argmax(1)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                image_idx = idx * loader.batch_size + i\n",
    "                pred_label = dataset.classes[predicted[i].item()]\n",
    "                true_label = dataset.classes[labels[i].item()]\n",
    "\n",
    "                if pred_label != true_label:\n",
    "                    misclassified.append((image_idx, pred_label, true_label))\n",
    "                    class_misclassification[true_label] += 1\n",
    "\n",
    "    print(\"\\n✅ 검증 데이터셋에서 자주 틀린 클래스 (상위 10개)\")\n",
    "    for label, count in class_misclassification.most_common(10):\n",
    "        print(f\"Class {label}: {count}번 오답 발생\")\n",
    "\n",
    "    return misclassified\n",
    "\n",
    "# ✅ 클래스별 정확도 확인\n",
    "def compute_classwise_accuracy(loader):\n",
    "    class_correct = Counter()\n",
    "    class_total = Counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.argmax(1)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                true_label = labels[i].item()\n",
    "                class_total[true_label] += 1\n",
    "                if predicted[i] == true_label:\n",
    "                    class_correct[true_label] += 1\n",
    "\n",
    "    class_accuracy = {}\n",
    "    print(\"\\n✅ 검증 데이터셋 클래스별 정확도:\")\n",
    "    for label in sorted(class_total.keys()):\n",
    "        accuracy = class_correct[label] / class_total[label] if class_total[label] > 0 else 0\n",
    "        class_accuracy[dataset.classes[label]] = accuracy\n",
    "        print(f\"Class {dataset.classes[label]}: {accuracy:.2%} 정확도\")\n",
    "\n",
    "    return class_accuracy\n",
    "\n",
    "# ✅ 확신도가 낮은 샘플 찾기\n",
    "def find_low_confidence_samples(loader, threshold=0.3):\n",
    "    low_confidence_samples = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            confidence, predicted = probabilities.max(1)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                image_idx = idx * loader.batch_size + i\n",
    "                if confidence[i].item() < threshold:  # 🔥 확신도가 낮은 샘플 저장\n",
    "                    low_confidence_samples.append((image_idx, dataset.classes[predicted[i].item()], dataset.classes[labels[i].item()], confidence[i].item()))\n",
    "\n",
    "    print(\"\\n✅ 검증 데이터셋에서 확신도가 낮은 샘플 (상위 10개)\")\n",
    "    for i, (image_idx, pred_label, true_label, conf) in enumerate(low_confidence_samples[:10]):\n",
    "        print(f\"이미지 {image_idx}: 예측={pred_label}, 실제={true_label}, 확신도={conf:.2f}\")\n",
    "\n",
    "    return low_confidence_samples\n",
    "\n",
    "# ✅ 실행\n",
    "print(\"\\n🔥 검증 데이터셋에서 문제있는 데이터 찾기 🔥\")\n",
    "misclassified_valid = find_misclassified_samples(valid_loader)\n",
    "class_accuracy = compute_classwise_accuracy(valid_loader)\n",
    "low_confidence_valid = find_low_confidence_samples(valid_loader)\n",
    "\n",
    "# ✅ CSV로 저장 (문제있는 데이터 정리)\n",
    "misclassified_df = pd.DataFrame(misclassified_valid, columns=[\"Image Index\", \"Predicted Label\", \"True Label\"])\n",
    "low_confidence_df = pd.DataFrame(low_confidence_valid, columns=[\"Image Index\", \"Predicted Label\", \"True Label\", \"Confidence\"])\n",
    "class_accuracy_df = pd.DataFrame(list(class_accuracy.items()), columns=[\"Class\", \"Accuracy\"])\n",
    "\n",
    "misclassified_csv = os.path.join(csv_dir, \"misclassified_samples.csv\")\n",
    "low_confidence_csv = os.path.join(csv_dir, \"low_confidence_samples.csv\")\n",
    "class_accuracy_csv = os.path.join(csv_dir, \"classwise_accuracy.csv\")\n",
    "\n",
    "misclassified_df.to_csv(misclassified_csv, index=False)\n",
    "low_confidence_df.to_csv(low_confidence_csv, index=False)\n",
    "class_accuracy_df.to_csv(class_accuracy_csv, index=False)\n",
    "\n",
    "print(f\"\\n📄 검증 데이터셋에서 오답이 많은 샘플 저장됨: {misclassified_csv}\")\n",
    "print(f\"📄 검증 데이터셋에서 확신도가 낮은 샘플 저장됨: {low_confidence_csv}\")\n",
    "print(f\"📄 클래스별 정확도 저장됨: {class_accuracy_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
