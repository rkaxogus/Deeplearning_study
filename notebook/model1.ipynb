{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 사용 중인 GPU: Quadro RTX 4000\n",
      "\n",
      "📢 Training Started! Logging Every Epoch:\n",
      "\n",
      "\n",
      "📢 Epoch [1/30] 시작\n",
      "   🎯 Train Accuracy: 0.7248 | 📉 Train Loss: 0.8655 | 🎯 Valid Accuracy: 0.7976 | 📉 Valid Loss: 0.6001\n",
      "🎯 새로운 최고 모델 저장됨! (Epoch 1, Accuracy: 0.7976)\n",
      "\n",
      "📢 Epoch [2/30] 시작\n",
      "   🎯 Train Accuracy: 0.8387 | 📉 Train Loss: 0.4997 | 🎯 Valid Accuracy: 0.8164 | 📉 Valid Loss: 0.6194\n",
      "🎯 새로운 최고 모델 저장됨! (Epoch 2, Accuracy: 0.8164)\n",
      "\n",
      "📢 Epoch [3/30] 시작\n",
      "   🎯 Train Accuracy: 0.8801 | 📉 Train Loss: 0.3607 | 🎯 Valid Accuracy: 0.8463 | 📉 Valid Loss: 0.5667\n",
      "🎯 새로운 최고 모델 저장됨! (Epoch 3, Accuracy: 0.8463)\n",
      "\n",
      "📢 Epoch [4/30] 시작\n",
      "   🎯 Train Accuracy: 0.9136 | 📉 Train Loss: 0.2660 | 🎯 Valid Accuracy: 0.8319 | 📉 Valid Loss: 0.5880\n",
      "\n",
      "📢 Epoch [5/30] 시작\n",
      "   🎯 Train Accuracy: 0.9278 | 📉 Train Loss: 0.2143 | 🎯 Valid Accuracy: 0.8485 | 📉 Valid Loss: 0.5894\n",
      "🎯 새로운 최고 모델 저장됨! (Epoch 5, Accuracy: 0.8485)\n",
      "\n",
      "📢 Epoch [6/30] 시작\n",
      "   🎯 Train Accuracy: 0.9366 | 📉 Train Loss: 0.1921 | 🎯 Valid Accuracy: 0.8561 | 📉 Valid Loss: 0.5549\n",
      "🎯 새로운 최고 모델 저장됨! (Epoch 6, Accuracy: 0.8561)\n",
      "\n",
      "📢 Epoch [7/30] 시작\n",
      "   🎯 Train Accuracy: 0.9444 | 📉 Train Loss: 0.1696 | 🎯 Valid Accuracy: 0.8485 | 📉 Valid Loss: 0.5791\n",
      "\n",
      "📢 Epoch [8/30] 시작\n",
      "   🎯 Train Accuracy: 0.9505 | 📉 Train Loss: 0.1493 | 🎯 Valid Accuracy: 0.8510 | 📉 Valid Loss: 0.5861\n",
      "\n",
      "📢 Epoch [9/30] 시작\n",
      "   🎯 Train Accuracy: 0.9624 | 📉 Train Loss: 0.1136 | 🎯 Valid Accuracy: 0.8615 | 📉 Valid Loss: 0.5668\n",
      "🎯 새로운 최고 모델 저장됨! (Epoch 9, Accuracy: 0.8615)\n",
      "\n",
      "📢 Epoch [10/30] 시작\n",
      "   🎯 Train Accuracy: 0.9569 | 📉 Train Loss: 0.1295 | 🎯 Valid Accuracy: 0.8438 | 📉 Valid Loss: 0.7044\n",
      "\n",
      "📢 Epoch [11/30] 시작\n",
      "   🎯 Train Accuracy: 0.9575 | 📉 Train Loss: 0.1263 | 🎯 Valid Accuracy: 0.8496 | 📉 Valid Loss: 0.6486\n",
      "\n",
      "📢 Epoch [12/30] 시작\n",
      "   🎯 Train Accuracy: 0.9711 | 📉 Train Loss: 0.0910 | 🎯 Valid Accuracy: 0.8449 | 📉 Valid Loss: 0.6967\n",
      "\n",
      "📢 Epoch [13/30] 시작\n",
      "   🎯 Train Accuracy: 0.9638 | 📉 Train Loss: 0.1069 | 🎯 Valid Accuracy: 0.8355 | 📉 Valid Loss: 0.7959\n",
      "\n",
      "📢 Epoch [14/30] 시작\n",
      "   🎯 Train Accuracy: 0.9646 | 📉 Train Loss: 0.1071 | 🎯 Valid Accuracy: 0.8420 | 📉 Valid Loss: 0.7369\n",
      "\n",
      "📢 Epoch [15/30] 시작\n",
      "   🎯 Train Accuracy: 0.9639 | 📉 Train Loss: 0.1106 | 🎯 Valid Accuracy: 0.8532 | 📉 Valid Loss: 0.6535\n",
      "\n",
      "📢 Epoch [16/30] 시작\n",
      "   🎯 Train Accuracy: 0.9730 | 📉 Train Loss: 0.0872 | 🎯 Valid Accuracy: 0.8521 | 📉 Valid Loss: 0.6722\n",
      "\n",
      "📢 Epoch [17/30] 시작\n",
      "   🎯 Train Accuracy: 0.9772 | 📉 Train Loss: 0.0712 | 🎯 Valid Accuracy: 0.8391 | 📉 Valid Loss: 0.6864\n",
      "\n",
      "📢 Epoch [18/30] 시작\n",
      "   🎯 Train Accuracy: 0.9756 | 📉 Train Loss: 0.0783 | 🎯 Valid Accuracy: 0.8344 | 📉 Valid Loss: 0.7220\n",
      "\n",
      "📢 Epoch [19/30] 시작\n",
      "   🎯 Train Accuracy: 0.9773 | 📉 Train Loss: 0.0696 | 🎯 Valid Accuracy: 0.8492 | 📉 Valid Loss: 0.7497\n",
      "\n",
      "📢 Epoch [20/30] 시작\n",
      "   🎯 Train Accuracy: 0.9750 | 📉 Train Loss: 0.0788 | 🎯 Valid Accuracy: 0.8391 | 📉 Valid Loss: 0.7786\n",
      "\n",
      "📢 Epoch [21/30] 시작\n",
      "   🎯 Train Accuracy: 0.9709 | 📉 Train Loss: 0.0874 | 🎯 Valid Accuracy: 0.8481 | 📉 Valid Loss: 0.7458\n",
      "\n",
      "📢 Epoch [22/30] 시작\n",
      "   🎯 Train Accuracy: 0.9770 | 📉 Train Loss: 0.0722 | 🎯 Valid Accuracy: 0.8618 | 📉 Valid Loss: 0.7098\n",
      "🎯 새로운 최고 모델 저장됨! (Epoch 22, Accuracy: 0.8618)\n",
      "\n",
      "📢 Epoch [23/30] 시작\n",
      "   🎯 Train Accuracy: 0.9763 | 📉 Train Loss: 0.0726 | 🎯 Valid Accuracy: 0.8521 | 📉 Valid Loss: 0.7124\n",
      "\n",
      "📢 Epoch [24/30] 시작\n",
      "   🎯 Train Accuracy: 0.9802 | 📉 Train Loss: 0.0658 | 🎯 Valid Accuracy: 0.8434 | 📉 Valid Loss: 0.7442\n",
      "\n",
      "📢 Epoch [25/30] 시작\n",
      "   🎯 Train Accuracy: 0.9853 | 📉 Train Loss: 0.0490 | 🎯 Valid Accuracy: 0.8510 | 📉 Valid Loss: 0.7611\n",
      "\n",
      "📢 Epoch [26/30] 시작\n",
      "   🎯 Train Accuracy: 0.9823 | 📉 Train Loss: 0.0549 | 🎯 Valid Accuracy: 0.8330 | 📉 Valid Loss: 0.8016\n",
      "\n",
      "📢 Epoch [27/30] 시작\n",
      "   🎯 Train Accuracy: 0.9764 | 📉 Train Loss: 0.0722 | 🎯 Valid Accuracy: 0.8247 | 📉 Valid Loss: 0.8272\n",
      "\n",
      "📢 Epoch [28/30] 시작\n",
      "   🎯 Train Accuracy: 0.9718 | 📉 Train Loss: 0.0853 | 🎯 Valid Accuracy: 0.8521 | 📉 Valid Loss: 0.7156\n",
      "\n",
      "📢 Epoch [29/30] 시작\n",
      "   🎯 Train Accuracy: 0.9839 | 📉 Train Loss: 0.0488 | 🎯 Valid Accuracy: 0.8575 | 📉 Valid Loss: 0.7046\n",
      "\n",
      "📢 Epoch [30/30] 시작\n",
      "   🎯 Train Accuracy: 0.9826 | 📉 Train Loss: 0.0548 | 🎯 Valid Accuracy: 0.8301 | 📉 Valid Loss: 0.8073\n",
      "📄 최고의 모델이 저장되었습니다: C:/Users/user/OneDrive/Desktop/Resnet182-real/model\\final_category_model.pth\n",
      "📄 학습 결과 CSV 저장됨: C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\\category_classification_results.csv\n",
      "✅ 학습 종료! 최고 성능을 기록한 Epoch: 22, 🎯 Train Accuracy: 0.9770, 📉 Train Loss: 0.0722, 🎯 Valid Accuracy: 0.8618, 📉 Valid Loss: 0.7098\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "import random\n",
    "\n",
    "# ✅ GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"✅ 사용 중인 GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# ✅ 경로 설정\n",
    "data_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/data/category_data\"\n",
    "model_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/model\"\n",
    "csv_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\"\n",
    "json_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/json\"  # ✅ JSON 저장 경로\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "os.makedirs(json_dir, exist_ok=True)  # ✅ JSON 저장 폴더 생성\n",
    "\n",
    "# ✅ 데이터셋 분할 인덱스 저장 경로\n",
    "train_indices_path = os.path.join(json_dir, \"model1train.json\")\n",
    "val_indices_path = os.path.join(json_dir, \"model1val.json\")\n",
    "test_indices_path = os.path.join(json_dir, \"model1test.json\")\n",
    "\n",
    "# ✅ 하이퍼파라미터 설정\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ✅ 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ✅ 데이터셋 로드\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# ✅ 각 클래스별 이미지 인덱스 분배\n",
    "class_indices = {cls: [] for cls in dataset.class_to_idx.values()}\n",
    "\n",
    "for idx, (path, label) in enumerate(dataset.samples):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# ✅ 각 클래스별로 7:2:1 비율로 분할 (학습:검증:테스트)\n",
    "train_indices, val_indices, test_indices = [], [], []\n",
    "\n",
    "for indices in class_indices.values():\n",
    "    random.shuffle(indices)  # 랜덤 셔플\n",
    "    num_total = len(indices)\n",
    "    num_train = int(num_total * 0.7)\n",
    "    num_val = int(num_total * 0.2)\n",
    "    num_test = num_total - num_train - num_val\n",
    "\n",
    "    train_indices.extend(indices[:num_train])\n",
    "    val_indices.extend(indices[num_train:num_train+num_val])\n",
    "    test_indices.extend(indices[num_train+num_val:])\n",
    "\n",
    "# ✅ 분할된 인덱스를 JSON 파일로 저장\n",
    "with open(train_indices_path, \"w\") as f:\n",
    "    json.dump(train_indices, f)\n",
    "with open(val_indices_path, \"w\") as f:\n",
    "    json.dump(val_indices, f)\n",
    "with open(test_indices_path, \"w\") as f:\n",
    "    json.dump(test_indices, f)\n",
    "\n",
    "# ✅ 데이터셋 분할\n",
    "dataset_train = Subset(dataset, train_indices)\n",
    "dataset_val = Subset(dataset, val_indices)\n",
    "dataset_test = Subset(dataset, test_indices)\n",
    "\n",
    "# ✅ 데이터 로더 설정\n",
    "test_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "train_loader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ✅ EfficientNet-B0 모델 정의\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(dataset.classes))\n",
    "model.to(device)\n",
    "\n",
    "# ✅ 손실 함수 및 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# ✅ 학습 루프\n",
    "best_valid_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "csv_path = os.path.join(csv_dir, \"category_classification_results.csv\")\n",
    "train_losses, valid_losses, train_accuracies, valid_accuracies = [], [], [], []\n",
    "\n",
    "print(\"\\n📢 Training Started! Logging Every Epoch:\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n📢 Epoch [{epoch+1}/{EPOCHS}] 시작\")\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss /= total_train\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # ✅ 검증 단계\n",
    "    model.eval()\n",
    "    valid_loss, valid_correct = 0, 0\n",
    "    total_valid = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "            valid_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_valid += labels.size(0)\n",
    "\n",
    "    valid_loss /= total_valid\n",
    "    valid_accuracy = valid_correct / total_valid\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "    print(f\"   🎯 Train Accuracy: {train_accuracy:.4f} | 📉 Train Loss: {train_loss:.4f} | \"\n",
    "        f\"🎯 Valid Accuracy: {valid_accuracy:.4f} | 📉 Valid Loss: {valid_loss:.4f}\")\n",
    "\n",
    "    if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "        best_epoch = epoch + 1\n",
    "        best_model_path = os.path.join(model_dir, \"best_category_model.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"🎯 새로운 최고 모델 저장됨! (Epoch {epoch+1}, Accuracy: {best_valid_accuracy:.4f})\")\n",
    "\n",
    "# ✅ 최고의 검증 정확도를 기록한 에포크 모델 저장\n",
    "model_save_path = os.path.join(model_dir, \"final_category_model.pth\")\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"📄 최고의 모델이 저장되었습니다: {model_save_path}\")\n",
    "\n",
    "# ✅ 결과 CSV 저장\n",
    "df = pd.DataFrame({\n",
    "    'Epoch': range(1, len(train_losses) + 1),\n",
    "    'Train Loss': train_losses,\n",
    "    'Valid Loss': valid_losses,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Valid Accuracy': valid_accuracies\n",
    "})\n",
    "csv_path = os.path.join(csv_dir, \"category_classification_results.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"📄 학습 결과 CSV 저장됨: {csv_path}\")\n",
    "\n",
    "# ✅ 검증 정확도가 가장 높은 에포크의 모든 정보 출력\n",
    "print(f\"✅ 학습 종료! 최고 성능을 기록한 Epoch: {best_epoch}, 🎯 Train Accuracy: {train_accuracies[best_epoch-1]:.4f}, 📉 Train Loss: {train_losses[best_epoch-1]:.4f}, 🎯 Valid Accuracy: {best_valid_accuracy:.4f}, 📉 Valid Loss: {valid_losses[best_epoch-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA Available: True\n",
      "✅ 사용 중인 GPU: Quadro RTX 4000\n",
      "✅ Train 데이터셋 정확도: 0.9954\n",
      "✅ Valid 데이터셋 정확도: 0.8618\n",
      "✅ Test 데이터셋 정확도: 0.8734\n",
      "📄 평가 결과 CSV 저장됨: C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\\category_classification_evaluation.csv\n",
      "📄 상세 평가 결과 저장됨: C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\\detailed_classification_results.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"✅ CUDA Available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ 사용 중인 GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ✅ 경로 설정\n",
    "data_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/data/category_data\"\n",
    "model_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet182-real\\model\\best_category_model.pth\"\n",
    "csv_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\"\n",
    "json_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/json\"  # ✅ JSON 저장 경로\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "# ✅ 데이터셋 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ✅ 데이터셋 로드\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# ✅ JSON에서 인덱스 로드\n",
    "def load_indices(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_indices = load_indices(os.path.join(json_dir, \"model1train.json\"))\n",
    "val_indices = load_indices(os.path.join(json_dir, \"model1val.json\"))\n",
    "test_indices = load_indices(os.path.join(json_dir, \"model1test.json\"))\n",
    "\n",
    "# ✅ 데이터셋 분할\n",
    "dataset_train = Subset(dataset, train_indices)\n",
    "dataset_val = Subset(dataset, val_indices)\n",
    "dataset_test = Subset(dataset, test_indices)\n",
    "\n",
    "# ✅ 데이터 로더 설정\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset_val, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ✅ 모델 불러오기\n",
    "model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(dataset.classes))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ✅ 평가 함수 정의\n",
    "def evaluate_model(loader, dataset_name):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.argmax(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                image_idx = idx * loader.batch_size + i\n",
    "                pred_label = dataset.classes[predicted[i].item()]\n",
    "                true_label = dataset.classes[labels[i].item()]\n",
    "                if pred_label == true_label:\n",
    "                    results.append(f\"[✅ 정답] 이미지 {image_idx}: 예측={pred_label}, 실제={true_label}\")\n",
    "                else:\n",
    "                    results.append(f\"[❌ 오답] 이미지 {image_idx}: 예측={pred_label}, 실제={true_label}\")\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f\"✅ {dataset_name} 데이터셋 정확도: {accuracy:.4f}\")\n",
    "    return accuracy, results\n",
    "\n",
    "# ✅ 평가 수행\n",
    "train_accuracy, train_results = evaluate_model(train_loader, \"Train\")\n",
    "valid_accuracy, valid_results = evaluate_model(valid_loader, \"Valid\")\n",
    "test_accuracy, test_results = evaluate_model(test_loader, \"Test\")\n",
    "\n",
    "# ✅ 정확도 및 리콜 값 CSV 저장\n",
    "df = pd.DataFrame({\n",
    "    'Dataset': ['Train', 'Valid', 'Test'],\n",
    "    'Accuracy': [train_accuracy, valid_accuracy, test_accuracy]\n",
    "})\n",
    "\n",
    "csv_path = os.path.join(csv_dir, \"category_classification_evaluation.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"📄 평가 결과 CSV 저장됨: {csv_path}\")\n",
    "\n",
    "# ✅ 상세 결과 저장\n",
    "detail_results_path = os.path.join(csv_dir, \"detailed_classification_results.txt\")\n",
    "with open(detail_results_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(train_results + valid_results + test_results))\n",
    "print(f\"📄 상세 평가 결과 저장됨: {detail_results_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 사용 중인 GPU: Quadro RTX 4000\n",
      "✅ Train 데이터셋 정확도: 0.9954\n",
      "✅ Valid 데이터셋 정확도: 0.8618\n",
      "✅ Test 데이터셋 정확도: 0.8734\n",
      "📄 틀린 이미지가 저장되었습니다 (train, valid, test): C:/Users/user/OneDrive/Desktop/Resnet182-real/wrong_images\n",
      "📄 평가 결과 CSV 저장됨: C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\\category_classification_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# ✅ GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"✅ 사용 중인 GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# ✅ 경로 설정\n",
    "data_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/data/category_data\"\n",
    "model_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/model\"\n",
    "csv_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\"\n",
    "json_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/json\"\n",
    "wrong_images_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/wrong_images\"  # 틀린 이미지를 저장할 경로\n",
    "\n",
    "# 새로운 디렉토리 생성\n",
    "os.makedirs(wrong_images_dir, exist_ok=True)\n",
    "\n",
    "# ✅ 데이터셋 로드\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# ✅ JSON에서 인덱스 로드\n",
    "def load_indices(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_indices = load_indices(os.path.join(json_dir, \"model1train.json\"))\n",
    "val_indices = load_indices(os.path.join(json_dir, \"model1val.json\"))\n",
    "test_indices = load_indices(os.path.join(json_dir, \"model1test.json\"))\n",
    "\n",
    "# ✅ 데이터셋 분할\n",
    "dataset_train = Subset(dataset, train_indices)\n",
    "dataset_val = Subset(dataset, val_indices)\n",
    "dataset_test = Subset(dataset, test_indices)\n",
    "\n",
    "# ✅ 데이터 로더 설정\n",
    "train_loader = DataLoader(dataset_train, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset_val, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# ✅ 모델 불러오기\n",
    "model_path = os.path.join(model_dir, \"best_category_model.pth\")  # 또는 \"final_category_model.pth\"\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(dataset.classes))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# ✅ 평가 함수 정의\n",
    "def evaluate_model(loader, dataset_name):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    wrong_images = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, labels) in enumerate(loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.argmax(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # 각 이미지에 대해 정답과 예측값 비교\n",
    "            for i in range(len(labels)):\n",
    "                img_path = loader.dataset.dataset.samples[idx * loader.batch_size + i][0]\n",
    "                true_label = dataset.classes[labels[i].item()]\n",
    "                pred_label = dataset.classes[predicted[i].item()]\n",
    "\n",
    "                # 틀린 이미지 정보 추출\n",
    "                if true_label != pred_label:\n",
    "                    wrong_images.append((pred_label, true_label, img_path))\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"✅ {dataset_name} 데이터셋 정확도: {accuracy:.4f}\")\n",
    "    return accuracy, wrong_images\n",
    "\n",
    "# ✅ 모델 평가\n",
    "train_accuracy, train_wrong_images = evaluate_model(train_loader, \"Train\")\n",
    "valid_accuracy, valid_wrong_images = evaluate_model(valid_loader, \"Valid\")\n",
    "test_accuracy, test_wrong_images = evaluate_model(test_loader, \"Test\")\n",
    "\n",
    "# ✅ 틀린 이미지를 새로운 폴더에 저장 (원본 폴더 구조를 유지하며 복사)\n",
    "def save_wrong_images(wrong_images, base_dir, save_dir):\n",
    "    for pred_label, true_label, img_path in wrong_images:\n",
    "        # 원본 폴더에서 이미지 경로 추출\n",
    "        class_folder = os.path.basename(os.path.dirname(img_path))\n",
    "        new_dir = os.path.join(save_dir, class_folder)\n",
    "        os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "        # 이미지 복사\n",
    "        shutil.copy(img_path, new_dir)\n",
    "\n",
    "# ✅ 각 데이터셋에서 틀린 이미지 저장\n",
    "save_wrong_images(train_wrong_images, data_dir, os.path.join(wrong_images_dir, \"train\"))\n",
    "save_wrong_images(valid_wrong_images, data_dir, os.path.join(wrong_images_dir, \"valid\"))\n",
    "save_wrong_images(test_wrong_images, data_dir, os.path.join(wrong_images_dir, \"test\"))\n",
    "\n",
    "print(f\"📄 틀린 이미지가 저장되었습니다 (train, valid, test): {wrong_images_dir}\")\n",
    "\n",
    "# ✅ 결과 CSV 저장\n",
    "df = pd.DataFrame({\n",
    "    'Dataset': ['Train', 'Valid', 'Test'],\n",
    "    'Accuracy': [train_accuracy, valid_accuracy, test_accuracy]\n",
    "})\n",
    "\n",
    "csv_path = os.path.join(csv_dir, \"category_classification_evaluation.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"📄 평가 결과 CSV 저장됨: {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
