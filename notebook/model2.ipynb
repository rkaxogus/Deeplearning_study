{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì‚¬ìš© ì¤‘ì¸ GPU: Quadro RTX 4000\n",
      "âœ… í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜: {0: 1488, 1: 689, 2: 1694, 3: 440, 4: 2687, 5: 1998, 6: 1476, 7: 1061, 8: 1061, 9: 1289}\n",
      "\n",
      "ğŸ“‚ ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: C:/Users/user/OneDrive/Desktop/Resnet182-real/json\\model2train.json, C:/Users/user/OneDrive/Desktop/Resnet182-real/json\\model2val.json, C:/Users/user/OneDrive/Desktop/Resnet182-real/json\\model2test.json\n",
      "\n",
      "ğŸ“¢ Training Started! Logging Every Epoch:\n",
      "\n",
      "\n",
      "ğŸ“¢ Epoch [1/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.7208 | ğŸ“‰ Train Loss: 0.8616 | ğŸ¯ Valid Accuracy: 0.8057 | ğŸ“‰ Valid Loss: 0.5990\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 1, Accuracy: 0.8057)\n",
      "\n",
      "ğŸ“¢ Epoch [2/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.8475 | ğŸ“‰ Train Loss: 0.4771 | ğŸ¯ Valid Accuracy: 0.8412 | ğŸ“‰ Valid Loss: 0.5388\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 2, Accuracy: 0.8412)\n",
      "\n",
      "ğŸ“¢ Epoch [3/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.8813 | ğŸ“‰ Train Loss: 0.3637 | ğŸ¯ Valid Accuracy: 0.8440 | ğŸ“‰ Valid Loss: 0.5037\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 3, Accuracy: 0.8440)\n",
      "\n",
      "ğŸ“¢ Epoch [4/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9125 | ğŸ“‰ Train Loss: 0.2686 | ğŸ¯ Valid Accuracy: 0.8548 | ğŸ“‰ Valid Loss: 0.5322\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 4, Accuracy: 0.8548)\n",
      "\n",
      "ğŸ“¢ Epoch [5/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9287 | ğŸ“‰ Train Loss: 0.2143 | ğŸ¯ Valid Accuracy: 0.8376 | ğŸ“‰ Valid Loss: 0.5779\n",
      "\n",
      "ğŸ“¢ Epoch [6/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9392 | ğŸ“‰ Train Loss: 0.1884 | ğŸ¯ Valid Accuracy: 0.8390 | ğŸ“‰ Valid Loss: 0.5885\n",
      "\n",
      "ğŸ“¢ Epoch [7/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9401 | ğŸ“‰ Train Loss: 0.1804 | ğŸ¯ Valid Accuracy: 0.8422 | ğŸ“‰ Valid Loss: 0.5874\n",
      "\n",
      "ğŸ“¢ Epoch [8/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9526 | ğŸ“‰ Train Loss: 0.1500 | ğŸ¯ Valid Accuracy: 0.8476 | ğŸ“‰ Valid Loss: 0.6320\n",
      "\n",
      "ğŸ“¢ Epoch [9/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9567 | ğŸ“‰ Train Loss: 0.1389 | ğŸ¯ Valid Accuracy: 0.8397 | ğŸ“‰ Valid Loss: 0.6620\n",
      "\n",
      "ğŸ“¢ Epoch [10/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9601 | ğŸ“‰ Train Loss: 0.1232 | ğŸ¯ Valid Accuracy: 0.8594 | ğŸ“‰ Valid Loss: 0.6163\n",
      "ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch 10, Accuracy: 0.8594)\n",
      "\n",
      "ğŸ“¢ Epoch [11/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9633 | ğŸ“‰ Train Loss: 0.1134 | ğŸ¯ Valid Accuracy: 0.8501 | ğŸ“‰ Valid Loss: 0.6290\n",
      "\n",
      "ğŸ“¢ Epoch [12/30] ì‹œì‘\n",
      "   ğŸ¯ Train Accuracy: 0.9625 | ğŸ“‰ Train Loss: 0.1194 | ğŸ¯ Valid Accuracy: 0.8555 | ğŸ“‰ Valid Loss: 0.6319\n",
      "\n",
      "ğŸ“¢ Epoch [13/30] ì‹œì‘\n"
     ]
    }
   ],
   "source": [
    "#model2.pth 85.9%\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… GPU ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ… ì‚¬ìš© ì¤‘ì¸ GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# âœ… ê²½ë¡œ ì„¤ì •\n",
    "data_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/data/category_data\"\n",
    "model_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/model\"\n",
    "csv_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/csv\"\n",
    "json_dir = \"C:/Users/user/OneDrive/Desktop/Resnet182-real/json\"  # JSON ì €ì¥ ê²½ë¡œ\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "os.makedirs(json_dir, exist_ok=True)  # JSON ì €ì¥ í´ë” ìƒì„±\n",
    "\n",
    "# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# âœ… ë°ì´í„° ì „ì²˜ë¦¬\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "# âœ… ê° í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ë¶„ë°°\n",
    "class_indices = {cls: [] for cls in dataset.class_to_idx.values()}\n",
    "\n",
    "for idx, (path, label) in enumerate(dataset.samples):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# âœ… ê° í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ í™•ì¸\n",
    "class_sample_count = {cls: len(indices) for cls, indices in class_indices.items()}\n",
    "print(\"âœ… í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:\", class_sample_count)\n",
    "\n",
    "# âœ… 1ê°œ ì´í•˜ì˜ ìƒ˜í”Œì„ ê°€ì§„ í´ë˜ìŠ¤ë¥¼ ì œì™¸\n",
    "class_indices_filtered = {cls: indices for cls, indices in class_indices.items() if len(indices) > 1}\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë¶„í• \n",
    "train_indices, val_indices, test_indices = [], [], []\n",
    "\n",
    "for cls, indices in class_indices_filtered.items():\n",
    "    # stratifyë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì„ì˜ë¡œ ë¶„í• \n",
    "    train, temp = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "    val, test = train_test_split(temp, test_size=0.33, random_state=42)\n",
    "\n",
    "    train_indices.extend(train)\n",
    "    val_indices.extend(val)\n",
    "    test_indices.extend(test)\n",
    "\n",
    "# âœ… ì¸ë±ìŠ¤ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "train_indices_path = os.path.join(json_dir, \"model2train.json\")\n",
    "val_indices_path = os.path.join(json_dir, \"model2val.json\")\n",
    "test_indices_path = os.path.join(json_dir, \"model2test.json\")\n",
    "\n",
    "with open(train_indices_path, \"w\") as f:\n",
    "    json.dump(train_indices, f)\n",
    "with open(val_indices_path, \"w\") as f:\n",
    "    json.dump(val_indices, f)\n",
    "with open(test_indices_path, \"w\") as f:\n",
    "    json.dump(test_indices, f)\n",
    "\n",
    "print(f\"\\nğŸ“‚ ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ: {train_indices_path}, {val_indices_path}, {test_indices_path}\")\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ ë¶„í• \n",
    "dataset_train = Subset(dataset, train_indices)\n",
    "dataset_val = Subset(dataset, val_indices)\n",
    "dataset_test = Subset(dataset, test_indices)\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë” ì„¤ì •\n",
    "train_loader = DataLoader(dataset=dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# âœ… ëª¨ë¸ ì´ˆê¸°í™”\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(dataset.classes))\n",
    "model.to(device)\n",
    "\n",
    "# âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# âœ… í•™ìŠµ ë£¨í”„\n",
    "best_valid_accuracy = 0.0\n",
    "best_epoch = 0\n",
    "csv_path = os.path.join(csv_dir, \"ì¹´í…Œê³ ë¦¬ëª¨ë¸2.csv\")\n",
    "train_losses, valid_losses, train_accuracies, valid_accuracies = [], [], [], []\n",
    "\n",
    "print(\"\\nğŸ“¢ Training Started! Logging Every Epoch:\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nğŸ“¢ Epoch [{epoch+1}/{EPOCHS}] ì‹œì‘\")\n",
    "    model.train()\n",
    "    train_loss, train_correct = 0, 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss /= total_train\n",
    "    train_accuracy = train_correct / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # âœ… ê²€ì¦ ë‹¨ê³„\n",
    "    model.eval()\n",
    "    valid_loss, valid_correct = 0, 0\n",
    "    total_valid = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item() * inputs.size(0)\n",
    "            valid_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_valid += labels.size(0)\n",
    "\n",
    "    valid_loss /= total_valid\n",
    "    valid_accuracy = valid_correct / total_valid\n",
    "    valid_losses.append(valid_loss)\n",
    "    valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "    print(f\"   ğŸ¯ Train Accuracy: {train_accuracy:.4f} | ğŸ“‰ Train Loss: {train_loss:.4f} | \"\n",
    "        f\"ğŸ¯ Valid Accuracy: {valid_accuracy:.4f} | ğŸ“‰ Valid Loss: {valid_loss:.4f}\")\n",
    "    \n",
    "    # âœ… ìµœê³ ì˜ ê²€ì¦ ì •í™•ë„ë¥¼ ê¸°ë¡í•œ ì—í¬í¬ ëª¨ë¸ ì €ì¥\n",
    "    if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "        best_epoch = epoch + 1\n",
    "        best_model_path = os.path.join(model_dir, \"model2.pth\")\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"ğŸ¯ ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥ë¨! (Epoch {epoch+1}, Accuracy: {best_valid_accuracy:.4f})\")\n",
    "\n",
    "# âœ… ê²°ê³¼ CSV ì €ì¥\n",
    "df = pd.DataFrame({\n",
    "    'Epoch': range(1, len(train_losses) + 1),\n",
    "    'Train Loss': train_losses,\n",
    "    'Valid Loss': valid_losses,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Valid Accuracy': valid_accuracies\n",
    "})\n",
    "csv_path = os.path.join(csv_dir, \"category_classification_results.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"ğŸ“„ í•™ìŠµ ê²°ê³¼ CSV ì €ì¥ë¨: {csv_path}\")\n",
    "\n",
    "# âœ… ê²€ì¦ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ì—í¬í¬ì˜ ëª¨ë“  ì •ë³´ ì¶œë ¥\n",
    "print(f\"âœ… í•™ìŠµ ì¢…ë£Œ! ìµœê³  ì„±ëŠ¥ì„ ê¸°ë¡í•œ Epoch: {best_epoch}, ğŸ¯ Train Accuracy: {train_accuracies[best_epoch-1]:.4f}, ğŸ“‰ Train Loss: {train_losses[best_epoch-1]:.4f}, ğŸ¯ Valid Accuracy: {best_valid_accuracy:.4f}, ğŸ“‰ Valid Loss: {valid_losses[best_epoch-1]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
