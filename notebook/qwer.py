#í´ë˜ìŠ¤ë³„ë¡œ ë¶„ë°° ì˜ë¨, ëª¨ë¸ì´ë¦„ model
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets, transforms
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights
import json
import csv
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import numpy as np
from torch.optim.lr_scheduler import StepLR
from torch.cuda.amp import GradScaler, autocast  # í˜¼í•© ì •ë°€ë„ í•™ìŠµ

os.environ["TORCH_COMPILE_DISABLE"] = "1"
os.environ["FUNCTORCH_COMPILE_DISABLE"] = "1"

# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
batch_size = 32
epochs = 1000
learning_rate = 0.001
early_stop_threshold = 0.99  # ì–¼ë¦¬ìŠ¤íƒ‘ ê¸°ì¤€ (ê²€ì¦ ì •í™•ë„ 99% ì´ìƒ)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# âœ… ê²½ë¡œ ì„¤ì •
train_dir = 'C:/Users/user/OneDrive/Desktop/Resnet182-real/data/category_data3'
json_dir = 'C:/Users/user/OneDrive/Desktop/Resnet182-real/jsonnew'
csv_dir = 'C:/Users/user/OneDrive/Desktop/Resnet182-real/csv'
model_dir = 'C:/Users/user/OneDrive/Desktop/Resnet182-real/model'

# í•„ìš”í•œ ë””ë ‰í„°ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
os.makedirs(json_dir, exist_ok=True)
os.makedirs(csv_dir, exist_ok=True)
os.makedirs(model_dir, exist_ok=True)

# âœ… ë°ì´í„° ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# âœ… ë°ì´í„°ì…‹ ë¡œë“œ
dataset = datasets.ImageFolder(root=train_dir, transform=transform)

# âœ… ë°ì´í„° ë¶„í•  (7:2:1 ë¹„ìœ¨)
train_data, temp_data = train_test_split(dataset.samples, test_size=0.3, stratify=dataset.targets)
val_data, test_data = train_test_split(temp_data, test_size=0.33, stratify=[item[1] for item in temp_data])

# âœ… JSON íŒŒì¼ë¡œ ë°ì´í„°ì…‹ ì €ì¥
train_json_path = os.path.join(json_dir, "trainqwer.json")
val_json_path = os.path.join(json_dir, "valqwer.json")
test_json_path = os.path.join(json_dir, "testqwer.json")

with open(train_json_path, "w") as f:
    json.dump(train_data, f)
with open(val_json_path, "w") as f:
    json.dump(val_data, f)
with open(test_json_path, "w") as f:
    json.dump(test_data, f)

print(f"âœ… í•™ìŠµ ë°ì´í„° JSON ì €ì¥ ì™„ë£Œ: {train_json_path}")
print(f"âœ… ê²€ì¦ ë°ì´í„° JSON ì €ì¥ ì™„ë£Œ: {val_json_path}")
print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° JSON ì €ì¥ ì™„ë£Œ: {test_json_path}")

# âœ… ë°ì´í„°ì…‹ì„ ìœ„í•œ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ ì •ì˜
class CustomDataset(Dataset):
    def __init__(self, data, dataset, transform=None):
        self.data = data
        self.dataset = dataset
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path, label = self.data[idx]
        image = self.dataset.loader(img_path)
        if self.transform:
            image = self.transform(image)
        return image, label

# âœ… í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë” ìƒì„±
train_dataset = CustomDataset(train_data, dataset, transform)
val_dataset = CustomDataset(val_data, dataset, transform)
test_dataset = CustomDataset(test_data, dataset, transform)

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# âœ… EfficientNet-B0 ëª¨ë¸ ì •ì˜
model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(dataset.classes))
model = model.to(device)

# âœ… ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# âœ… í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
scheduler = StepLR(optimizer, step_size=10, gamma=0.7)

# âœ… í˜¼í•© ì •ë°€ë„ í•™ìŠµ ìŠ¤ì¼€ì¼ëŸ¬
scaler = GradScaler()

# âœ… ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜
def evaluate(model, dataloader):
    model.eval()
    correct = 0
    total = 0
    running_loss = 0.0
    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = correct / total
    avg_loss = running_loss / len(dataloader)
    return accuracy, avg_loss

# âœ… í•™ìŠµ ë£¨í”„ ì¶”ê°€
best_val_acc = 0.0
best_epoch = 0
best_model_weights = None
epoch_log = []

print("\nğŸ“¢ Training Started! Logging Every Epoch:\n")

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for inputs, labels in tqdm(train_loader, desc=f"ğŸ“¢ Epoch [{epoch+1}/{epochs}] ì‹œì‘"):
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        with autocast():
            outputs = model(inputs)
            loss = criterion(outputs, labels)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_acc = correct / total
    train_loss = running_loss / len(train_loader)

    # âœ… ê²€ì¦ ë‹¨ê³„
    val_acc, val_loss = evaluate(model, val_loader)

    if val_acc > best_val_acc:
        best_val_acc = val_acc
        best_epoch = epoch + 1
        best_model_weights = model.state_dict()

    epoch_log.append([epoch + 1, train_acc, train_loss, val_acc, val_loss])

    print(f"   ğŸ¯ Train Accuracy: {train_acc:.4f} | ğŸ“‰ Train Loss: {train_loss:.4f} "
        f"| ğŸ¯ Valid Accuracy: {val_acc:.4f} | ğŸ“‰ Valid Loss: {val_loss:.4f}")

    if val_acc >= early_stop_threshold:
        print(f"ğŸš¨ ì–¼ë¦¬ìŠ¤íƒ‘! ê²€ì¦ ì •í™•ë„ê°€ {val_acc:.4f}ë¡œ 0.99ì— ë„ë‹¬í•˜ì—¬ í•™ìŠµì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    scheduler.step()

# âœ… ìµœìƒì˜ ëª¨ë¸ ì €ì¥
model.load_state_dict(best_model_weights)
torch.save(model.state_dict(), os.path.join(model_dir, 'model3new.pth'))

# âœ… í•™ìŠµ ê¸°ë¡ì„ CSV íŒŒì¼ë¡œ ì €ì¥
with open(os.path.join(csv_dir, 'training_log.csv'), 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['Epoch', 'Train Accuracy', 'Train Loss', 'Val Accuracy', 'Val Loss'])
    writer.writerows(epoch_log)

# âœ… ìµœì¢… ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ í‰ê°€
test_acc, test_loss = evaluate(model, test_loader)
print(f"ğŸ¯ Test Accuracy: {test_acc:.4f}, ğŸ“‰ Test Loss: {test_loss:.4f}")
