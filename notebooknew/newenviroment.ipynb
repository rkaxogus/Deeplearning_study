{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 모든 제품 폴더를 'processed_data3'로 이동 완료!\n",
      "총 클래스 개수: 57\n",
      "클래스 목록: ['12X', '4S 와이드', '6.3', 'A5', 'A7', 'IE', 'P1', 'X5', '가마보코', '날로', '노나돔', '니악', '도크돔', '라이더스', '랜드록', '랜드브리즈', '레이사', '리빙쉘', '문라이트', '미라클패밀리', '바랑에르돔', '발할', '뱅가드', '브이타프', '비무르', '비바돔', '빌리지', '새턴 쉘터', '새턴2룸', '솔로', '쉘터G', '스텔라릿지', '아고라', '아스가르드', '아퀼라', '아틀라스', '아티카', '알베르게', '알파인돔', '알페임', '어메니티돔', '오토듀얼팔레스', '와가야노', '우나', '우트가르드', '웨더마스터', '인디아나', '인스턴트업 3p', '캥거루', '코트텐트', '크로노스', '클라우드업', '투어링돔', '파프리카', '패스빅', '퍼시픽오션', '필드터널']\n",
      "✅ train3.json 저장 완료!\n",
      "✅ val3.json 저장 완료!\n",
      "✅ test3.json 저장 완료!\n",
      "✅ 데이터 로더 생성 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\classification3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\classification3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Epoch [1/500] | 📉 Train Loss: 2.0249 | 🎯 Train Accuracy: 53.3275 | 📑 Valid Loss: 1.1204 | 🎯 Valid Accuracy: 73.0817\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 1, Accuracy: 73.0817) ✅\n",
      "🚀 Epoch [2/500] | 📉 Train Loss: 0.8241 | 🎯 Train Accuracy: 81.3835 | 📑 Valid Loss: 0.7782 | 🎯 Valid Accuracy: 79.5173\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 2, Accuracy: 79.5173) ✅\n",
      "🚀 Epoch [3/500] | 📉 Train Loss: 0.5300 | 🎯 Train Accuracy: 87.6007 | 📑 Valid Loss: 0.6662 | 🎯 Valid Accuracy: 82.2401\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 3, Accuracy: 82.2401) ✅\n",
      "🚀 Epoch [4/500] | 📉 Train Loss: 0.3761 | 🎯 Train Accuracy: 90.5429 | 📑 Valid Loss: 0.6715 | 🎯 Valid Accuracy: 82.3639\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 4, Accuracy: 82.3639) ✅\n",
      "🚀 Epoch [5/500] | 📉 Train Loss: 0.3049 | 🎯 Train Accuracy: 91.9089 | 📑 Valid Loss: 0.6534 | 🎯 Valid Accuracy: 83.2302\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 5, Accuracy: 83.2302) ✅\n",
      "🚀 Epoch [6/500] | 📉 Train Loss: 0.2564 | 🎯 Train Accuracy: 93.0648 | 📑 Valid Loss: 0.6412 | 🎯 Valid Accuracy: 82.6114\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [7/500] | 📉 Train Loss: 0.2287 | 🎯 Train Accuracy: 93.5201 | 📑 Valid Loss: 0.7111 | 🎯 Valid Accuracy: 81.6832\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [8/500] | 📉 Train Loss: 0.2105 | 🎯 Train Accuracy: 93.6077 | 📑 Valid Loss: 0.6253 | 🎯 Valid Accuracy: 83.2921\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 8, Accuracy: 83.2921) ✅\n",
      "🚀 Epoch [9/500] | 📉 Train Loss: 0.1938 | 🎯 Train Accuracy: 94.0630 | 📑 Valid Loss: 0.6561 | 🎯 Valid Accuracy: 82.9827\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [10/500] | 📉 Train Loss: 0.1784 | 🎯 Train Accuracy: 94.1856 | 📑 Valid Loss: 0.6634 | 🎯 Valid Accuracy: 83.2921\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [11/500] | 📉 Train Loss: 0.1692 | 🎯 Train Accuracy: 94.2207 | 📑 Valid Loss: 0.7186 | 🎯 Valid Accuracy: 81.1262\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [12/500] | 📉 Train Loss: 0.1684 | 🎯 Train Accuracy: 94.1156 | 📑 Valid Loss: 0.6701 | 🎯 Valid Accuracy: 83.2921\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [13/500] | 📉 Train Loss: 0.1533 | 🎯 Train Accuracy: 94.6760 | 📑 Valid Loss: 0.6705 | 🎯 Valid Accuracy: 82.8589\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [14/500] | 📉 Train Loss: 0.1580 | 🎯 Train Accuracy: 94.5009 | 📑 Valid Loss: 0.7161 | 🎯 Valid Accuracy: 81.9926\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [15/500] | 📉 Train Loss: 0.1510 | 🎯 Train Accuracy: 94.3433 | 📑 Valid Loss: 0.6905 | 🎯 Valid Accuracy: 82.3639\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [16/500] | 📉 Train Loss: 0.1503 | 🎯 Train Accuracy: 94.6410 | 📑 Valid Loss: 0.7064 | 🎯 Valid Accuracy: 82.9827\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [17/500] | 📉 Train Loss: 0.1458 | 🎯 Train Accuracy: 94.3958 | 📑 Valid Loss: 0.7236 | 🎯 Valid Accuracy: 82.4257\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [18/500] | 📉 Train Loss: 0.1400 | 🎯 Train Accuracy: 94.4133 | 📑 Valid Loss: 0.7017 | 🎯 Valid Accuracy: 82.5495\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [19/500] | 📉 Train Loss: 0.1362 | 🎯 Train Accuracy: 94.8161 | 📑 Valid Loss: 0.7433 | 🎯 Valid Accuracy: 81.0644\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-05.\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [20/500] | 📉 Train Loss: 0.1147 | 🎯 Train Accuracy: 95.1138 | 📑 Valid Loss: 0.7363 | 🎯 Valid Accuracy: 82.1782\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [21/500] | 📉 Train Loss: 0.1018 | 🎯 Train Accuracy: 95.4291 | 📑 Valid Loss: 0.7471 | 🎯 Valid Accuracy: 82.6733\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [22/500] | 📉 Train Loss: 0.0992 | 🎯 Train Accuracy: 95.3240 | 📑 Valid Loss: 0.7140 | 🎯 Valid Accuracy: 83.9728\n",
      "현재 학습률: 0.000050\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 22, Accuracy: 83.9728) ✅\n",
      "🚀 Epoch [23/500] | 📉 Train Loss: 0.0965 | 🎯 Train Accuracy: 95.3765 | 📑 Valid Loss: 0.7392 | 🎯 Valid Accuracy: 82.7351\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [24/500] | 📉 Train Loss: 0.0959 | 🎯 Train Accuracy: 95.5342 | 📑 Valid Loss: 0.7408 | 🎯 Valid Accuracy: 83.2302\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [25/500] | 📉 Train Loss: 0.0940 | 🎯 Train Accuracy: 95.1489 | 📑 Valid Loss: 0.7848 | 🎯 Valid Accuracy: 81.6832\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [26/500] | 📉 Train Loss: 0.0933 | 🎯 Train Accuracy: 95.5692 | 📑 Valid Loss: 0.7769 | 🎯 Valid Accuracy: 82.8589\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [27/500] | 📉 Train Loss: 0.0972 | 🎯 Train Accuracy: 95.0963 | 📑 Valid Loss: 0.7827 | 🎯 Valid Accuracy: 82.8589\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [28/500] | 📉 Train Loss: 0.0946 | 🎯 Train Accuracy: 95.4991 | 📑 Valid Loss: 0.7796 | 🎯 Valid Accuracy: 83.0446\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [29/500] | 📉 Train Loss: 0.0942 | 🎯 Train Accuracy: 95.2189 | 📑 Valid Loss: 0.7831 | 🎯 Valid Accuracy: 82.3639\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [30/500] | 📉 Train Loss: 0.0912 | 🎯 Train Accuracy: 95.3940 | 📑 Valid Loss: 0.7964 | 🎯 Valid Accuracy: 82.3020\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [31/500] | 📉 Train Loss: 0.0904 | 🎯 Train Accuracy: 95.3940 | 📑 Valid Loss: 0.8021 | 🎯 Valid Accuracy: 81.9926\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [32/500] | 📉 Train Loss: 0.0880 | 🎯 Train Accuracy: 95.6918 | 📑 Valid Loss: 0.8100 | 🎯 Valid Accuracy: 82.3020\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [33/500] | 📉 Train Loss: 0.0894 | 🎯 Train Accuracy: 95.6042 | 📑 Valid Loss: 0.8437 | 🎯 Valid Accuracy: 81.5594\n",
      "Epoch 00033: reducing learning rate of group 0 to 2.5000e-05.\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [34/500] | 📉 Train Loss: 0.0810 | 🎯 Train Accuracy: 95.6042 | 📑 Valid Loss: 0.8038 | 🎯 Valid Accuracy: 82.1782\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [35/500] | 📉 Train Loss: 0.0767 | 🎯 Train Accuracy: 95.7443 | 📑 Valid Loss: 0.8262 | 🎯 Valid Accuracy: 82.3639\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [36/500] | 📉 Train Loss: 0.0730 | 🎯 Train Accuracy: 96.0245 | 📑 Valid Loss: 0.8404 | 🎯 Valid Accuracy: 82.3020\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [37/500] | 📉 Train Loss: 0.0745 | 🎯 Train Accuracy: 95.8144 | 📑 Valid Loss: 0.8079 | 🎯 Valid Accuracy: 82.6733\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [38/500] | 📉 Train Loss: 0.0767 | 🎯 Train Accuracy: 95.6918 | 📑 Valid Loss: 0.8477 | 🎯 Valid Accuracy: 82.4257\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [39/500] | 📉 Train Loss: 0.0731 | 🎯 Train Accuracy: 95.9194 | 📑 Valid Loss: 0.8239 | 🎯 Valid Accuracy: 82.8589\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [40/500] | 📉 Train Loss: 0.0771 | 🎯 Train Accuracy: 95.7618 | 📑 Valid Loss: 0.8457 | 🎯 Valid Accuracy: 82.2401\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [41/500] | 📉 Train Loss: 0.0745 | 🎯 Train Accuracy: 95.8319 | 📑 Valid Loss: 0.8600 | 🎯 Valid Accuracy: 82.3020\n",
      "현재 학습률: 0.000025\n",
      "🚀 Epoch [42/500] | 📉 Train Loss: 0.0733 | 🎯 Train Accuracy: 95.6567 | 📑 Valid Loss: 0.8393 | 🎯 Valid Accuracy: 82.3639\n",
      "현재 학습률: 0.000025\n",
      "🚨 조기 종료: 20 에폭 동안 개선 없음.\n",
      "🎯 최종 최고 검증 정확도: 83.97%\n",
      "✅ 학습 기록 저장 완료: C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\csv\\텐트분류3.csv\n",
      "🎯 테스트 데이터셋 정확도: 81.31%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset  # [변경됨]: random_split 대신 Subset 사용\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np  # [변경됨]: numpy 임포트\n",
    "\n",
    "# [추가됨] 재현성을 위한 시드 설정\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 데이터 경로 설정\n",
    "data_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\data\\brand_data3\"\n",
    "processed_data_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\data\\processed_data3\"\n",
    "json_save_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\json\"\n",
    "csv_save_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\csv\"\n",
    "model_save_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\modelnew\\resnet18-3.pth\"\n",
    "\n",
    "# JSON, CSV 저장 폴더 생성\n",
    "os.makedirs(json_save_dir, exist_ok=True)\n",
    "os.makedirs(csv_save_dir, exist_ok=True)\n",
    "\n",
    "# 모든 브랜드 폴더를 순회하면서 하위 제품 폴더 이동\n",
    "for brand in os.listdir(data_dir):\n",
    "    brand_path = os.path.join(data_dir, brand)\n",
    "    if os.path.isdir(brand_path):\n",
    "        for product in os.listdir(brand_path):\n",
    "            product_path = os.path.join(brand_path, product)\n",
    "            if os.path.isdir(product_path):\n",
    "                new_product_path = os.path.join(processed_data_dir, product)\n",
    "                os.makedirs(new_product_path, exist_ok=True)\n",
    "                for image in os.listdir(product_path):\n",
    "                    src = os.path.join(product_path, image)\n",
    "                    dst = os.path.join(new_product_path, image)\n",
    "                    shutil.copy(src, dst)\n",
    "\n",
    "print(\"✅ 모든 제품 폴더를 'processed_data3'로 이동 완료!\")\n",
    "\n",
    "# 이미지 변환 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = datasets.ImageFolder(root=processed_data_dir, transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "print(f\"총 클래스 개수: {num_classes}\")\n",
    "print(\"클래스 목록:\", dataset.classes)\n",
    "\n",
    "# [변경됨] 데이터셋 분할 - 클래스별로 7:2:1 비율로 분할\n",
    "# 각 클래스별 인덱스 추출\n",
    "class_indices = {cls: [] for cls in range(num_classes)}\n",
    "for idx, (path, label) in enumerate(dataset.imgs):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "train_indices, val_indices, test_indices = [], [], []\n",
    "for label, indices in class_indices.items():\n",
    "    np.random.shuffle(indices)  # 인덱스 랜덤 셔플\n",
    "    n = len(indices)\n",
    "    n_train = int(0.7 * n)\n",
    "    n_val = int(0.2 * n)\n",
    "    # 나머지는 테스트셋에 할당\n",
    "    train_indices.extend(indices[:n_train])\n",
    "    val_indices.extend(indices[n_train:n_train+n_val])\n",
    "    test_indices.extend(indices[n_train+n_val:])\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "# [변경됨 끝]\n",
    "\n",
    "# JSON 파일로 데이터셋 저장\n",
    "def save_json(subset_dataset, dataset_name):\n",
    "    data_list = [{\"image_path\": subset_dataset.dataset.imgs[i][0], \"label\": int(subset_dataset.dataset.imgs[i][1])} \n",
    "                for i in subset_dataset.indices]\n",
    "    json_path = os.path.join(json_save_dir, f\"{dataset_name}.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data_list, f, indent=4)\n",
    "    print(f\"✅ {dataset_name}.json 저장 완료!\")\n",
    "\n",
    "save_json(train_dataset, \"train3\")\n",
    "save_json(val_dataset, \"val3\")\n",
    "save_json(test_dataset, \"test3\")\n",
    "\n",
    "# 데이터 로더 설정\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"✅ 데이터 로더 생성 완료!\")\n",
    "\n",
    "# 모델 설정 (ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# 손실 함수 및 최적화 함수 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "# [추가됨] Learning rate scheduler (ReduceLROnPlateau 사용 - 검증 정확도를 기준으로 학습률 조절)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "# 학습 기록 저장용 DataFrame\n",
    "history = {\"epoch\": [], \"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "# [추가됨] Early Stopping 설정 변수 (개선이 없을 시 조기 종료)\n",
    "early_stop_patience = 20\n",
    "no_improve_count = 0\n",
    "\n",
    "# [추가됨] 로그 파일 생성 (학습 기록 추가 저장)\n",
    "log_file = os.path.join(csv_save_dir, \"train_log3.txt\")\n",
    "with open(log_file, \"w\") as lf:\n",
    "    lf.write(\"Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Learning Rate\\n\")\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "    global no_improve_count  # [추가됨] early stopping 카운트 변수 사용\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_train += predicted.eq(labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct_val += predicted.eq(labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"🚀 Epoch [{epoch+1}/{num_epochs}] | 📉 Train Loss: {train_loss:.4f} | 🎯 Train Accuracy: {train_acc:.4f} | 📑 Valid Loss: {val_loss:.4f} | 🎯 Valid Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # [추가됨] Learning rate scheduler step (검증 정확도를 기준으로 학습률 조정)\n",
    "        scheduler.step(val_acc)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"현재 학습률: {current_lr:.6f}\")\n",
    "\n",
    "        # [추가됨] 로그 파일에 학습 기록 추가 저장\n",
    "        with open(log_file, \"a\") as lf:\n",
    "            lf.write(f\"{epoch+1},{train_loss:.4f},{train_acc:.4f},{val_loss:.4f},{val_acc:.4f},{current_lr:.6f}\\n\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"📌 새로운 최고 모델 저장됨! (Epoch {epoch+1}, Accuracy: {val_acc:.4f}) ✅\")\n",
    "            no_improve_count = 0  # [추가됨] 개선되었으므로 카운트 초기화\n",
    "        else:\n",
    "            no_improve_count += 1  # [추가됨] 개선되지 않음\n",
    "\n",
    "        # [추가됨] Early Stopping 조건 확인 (개선이 없으면 조기 종료)\n",
    "        if no_improve_count >= early_stop_patience:\n",
    "            print(f\"🚨 조기 종료: {early_stop_patience} 에폭 동안 개선 없음.\")\n",
    "            break\n",
    "\n",
    "    print(f\"🎯 최종 최고 검증 정확도: {best_acc:.2f}%\")\n",
    "\n",
    "# 모델 학습 실행\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=500)\n",
    "\n",
    "# 학습 과정 CSV로 저장\n",
    "df = pd.DataFrame(history)\n",
    "csv_path = os.path.join(csv_save_dir, \"텐트분류3.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 학습 기록 저장 완료: {csv_path}\")\n",
    "\n",
    "# 최적 모델 로드 후 테스트 데이터 평가\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "correct_test, total_test = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_test += predicted.eq(labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "test_acc = 100 * correct_test / total_test\n",
    "print(f\"🎯 테스트 데이터셋 정확도: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Module', '_HAS_OPS', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_image_backend', '_internally_replaced_utils', '_is_tracing', '_meta_registrations', '_utils', '_video_backend', 'datasets', 'disable_beta_transforms_warning', 'extension', 'get_image_backend', 'get_video_backend', 'io', 'models', 'ops', 'os', 'set_image_backend', 'set_video_backend', 'torch', 'transforms', 'utils', 'version', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "print(dir(torchvision))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
