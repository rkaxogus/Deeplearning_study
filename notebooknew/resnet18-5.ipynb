{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✅ 모든 제품 폴더를 'processed_data5'로 이동 완료!\n",
      "총 클래스 개수: 171\n",
      "클래스 목록: ['12X', '17.2', '4S 와이드', '6.3', 'A5', 'A7', 'A9', 'D1', 'IE', 'M1', 'P1', 'T 코어', 'U.L', 'X 코어', 'X5', 'protect', '가마보코', '고스트', '고틀랜드', '골드키위', '구아바', '그랑베르크', '그랜즈빌 렉타 타프', '나르시스 돔', '나마츠', '날로', '네뷸라', '네스트', '노나돔', '니악', '데크쉘터', '도크돔', '라이더스', '라인스피엘', '랜드록', '랜드마크', '랜드브리즈', '레이사', '렉타', '렉타 타프', '렉타타프', '로맨틱터틀', '루나', '리빙쉘', '링스틴드', '마리나', '멀티펑션 암막타프', '메쉬 타프스크린', '몽가', '문라이트', '미라클스크린', '미라클패밀리', '바랑에르', '바랑에르돔', '발할', '뱅가드', '보니아또', '보스', '볼트', '브이타프', '블랙 코트', '비무르', '비바 렉타 타프', '비바돔', '비티호른', '빅', '빌리지', '새턴 쉘터', '새턴 에어텐트', '새턴2룸', '세이랜드', '셰어', '솔로', '쉘터G', '쉘터돔', '슈퍼팰리스', '스타이카', '스텔라릿지', '썬블럭', '아고라', '아리에스', '아스가르드', '아스터돔', '아스트라돔', '아케디아', '아퀼라', '아틀라스', '아틀란틱', '아티카', '알락', '알베르게', '알비온', '알파 룸', '알파인돔', '알파인라이트', '알페임', '야른비드', '어메니티돔', '에볼루션 메쉬쉘터', '에어 도킹', '에어 리빙 쉘터', '에코 소울 예이예이', '옐로우스톤', '오우치', '오토듀얼팔레스', '오토하우스', '오트라', '오파러스', '오프랜드', '와가야노', '와이즈 타프쉘', '와일드 필드 오스카', '와일드 필드 옥타곤', '와일드 필드 헥사 타프', '우나', '우르사', '우트가르드', '워터멜론', '원터치', '웨더마스터', '이너텐트', '이든', '이지팝', '인디아나', '인스턴트업 3p', '인스턴트업돔', '제드7', '제이스타', '지오패스', '카리', '카바나', '카이텀', '카텐트', '카프리콘', '캐슬', '캥거루', '컴팩트 원터치', '케론', '케팔로', '코트텐트', '크로노스', '크로스 빅쉘터', '클라우드업', '클라우드피크', '키노코', '타우루스', '탠저린', '터프돔', '터프스크린', '터프와이드돔', '투띠', '투어링', '투어링돔', '트리온', '티어돔', '파노라마', '파티캐빈', '파프리카', '팝업', '패스빅', '퍼시픽오션', '폰피엘', '폼므', '플레이어', '필드터널', '하우스', '하이비', '할란드', '헥사 타프', '헬락스', '휘떼']\n",
      "✅ train5.json 저장 완료!\n",
      "✅ val5.json 저장 완료!\n",
      "✅ test5.json 저장 완료!\n",
      "✅ 데이터 로더 생성 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\classification3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\user\\anaconda3\\envs\\classification3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Epoch [1/500] | 📉 Train Loss: 3.3700 | 🎯 Train Accuracy: 34.2060 | 📑 Valid Loss: 2.2753 | 🎯 Valid Accuracy: 53.6799\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 1, Accuracy: 53.6799) ✅\n",
      "🚀 Epoch [2/500] | 📉 Train Loss: 1.9650 | 🎯 Train Accuracy: 60.7665 | 📑 Valid Loss: 1.7908 | 🎯 Valid Accuracy: 62.0189\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 2, Accuracy: 62.0189) ✅\n",
      "🚀 Epoch [3/500] | 📉 Train Loss: 1.4303 | 🎯 Train Accuracy: 70.2428 | 📑 Valid Loss: 1.5358 | 🎯 Valid Accuracy: 66.2728\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 3, Accuracy: 66.2728) ✅\n",
      "🚀 Epoch [4/500] | 📉 Train Loss: 1.1046 | 🎯 Train Accuracy: 75.7067 | 📑 Valid Loss: 1.4429 | 🎯 Valid Accuracy: 67.4882\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 4, Accuracy: 67.4882) ✅\n",
      "🚀 Epoch [5/500] | 📉 Train Loss: 0.8820 | 🎯 Train Accuracy: 80.0133 | 📑 Valid Loss: 1.4026 | 🎯 Valid Accuracy: 68.6361\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 5, Accuracy: 68.6361) ✅\n",
      "🚀 Epoch [6/500] | 📉 Train Loss: 0.7096 | 🎯 Train Accuracy: 83.0393 | 📑 Valid Loss: 1.3646 | 🎯 Valid Accuracy: 68.9737\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 6, Accuracy: 68.9737) ✅\n",
      "🚀 Epoch [7/500] | 📉 Train Loss: 0.5911 | 🎯 Train Accuracy: 85.4297 | 📑 Valid Loss: 1.3616 | 🎯 Valid Accuracy: 68.7373\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [8/500] | 📉 Train Loss: 0.5030 | 🎯 Train Accuracy: 86.9759 | 📑 Valid Loss: 1.3740 | 🎯 Valid Accuracy: 69.5138\n",
      "현재 학습률: 0.000100\n",
      "📌 새로운 최고 모델 저장됨! (Epoch 8, Accuracy: 69.5138) ✅\n",
      "🚀 Epoch [9/500] | 📉 Train Loss: 0.4440 | 🎯 Train Accuracy: 88.2091 | 📑 Valid Loss: 1.4236 | 🎯 Valid Accuracy: 67.2856\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [10/500] | 📉 Train Loss: 0.4101 | 🎯 Train Accuracy: 88.4272 | 📑 Valid Loss: 1.3908 | 🎯 Valid Accuracy: 68.6698\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [11/500] | 📉 Train Loss: 0.3906 | 🎯 Train Accuracy: 88.6454 | 📑 Valid Loss: 1.4327 | 🎯 Valid Accuracy: 67.5219\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [12/500] | 📉 Train Loss: 0.3698 | 🎯 Train Accuracy: 89.0913 | 📑 Valid Loss: 1.4772 | 🎯 Valid Accuracy: 66.9142\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [13/500] | 📉 Train Loss: 0.3451 | 🎯 Train Accuracy: 89.4897 | 📑 Valid Loss: 1.4761 | 🎯 Valid Accuracy: 66.9818\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [14/500] | 📉 Train Loss: 0.3365 | 🎯 Train Accuracy: 89.2525 | 📑 Valid Loss: 1.4657 | 🎯 Valid Accuracy: 67.6232\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [15/500] | 📉 Train Loss: 0.3257 | 🎯 Train Accuracy: 89.4991 | 📑 Valid Loss: 1.5235 | 🎯 Valid Accuracy: 67.5557\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [16/500] | 📉 Train Loss: 0.3125 | 🎯 Train Accuracy: 89.7837 | 📑 Valid Loss: 1.4809 | 🎯 Valid Accuracy: 67.1168\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [17/500] | 📉 Train Loss: 0.3005 | 🎯 Train Accuracy: 89.8596 | 📑 Valid Loss: 1.5003 | 🎯 Valid Accuracy: 67.5219\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [18/500] | 📉 Train Loss: 0.2921 | 🎯 Train Accuracy: 89.8691 | 📑 Valid Loss: 1.5447 | 🎯 Valid Accuracy: 66.3065\n",
      "현재 학습률: 0.000100\n",
      "🚀 Epoch [19/500] | 📉 Train Loss: 0.2981 | 🎯 Train Accuracy: 89.7363 | 📑 Valid Loss: 1.5429 | 🎯 Valid Accuracy: 66.9142\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-05.\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [20/500] | 📉 Train Loss: 0.2401 | 🎯 Train Accuracy: 90.7608 | 📑 Valid Loss: 1.4852 | 🎯 Valid Accuracy: 68.7711\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [21/500] | 📉 Train Loss: 0.2159 | 🎯 Train Accuracy: 91.1023 | 📑 Valid Loss: 1.5058 | 🎯 Valid Accuracy: 68.6361\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [22/500] | 📉 Train Loss: 0.2146 | 🎯 Train Accuracy: 91.1687 | 📑 Valid Loss: 1.5095 | 🎯 Valid Accuracy: 68.3660\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [23/500] | 📉 Train Loss: 0.2092 | 🎯 Train Accuracy: 90.7703 | 📑 Valid Loss: 1.4999 | 🎯 Valid Accuracy: 68.4673\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [24/500] | 📉 Train Loss: 0.2054 | 🎯 Train Accuracy: 91.0548 | 📑 Valid Loss: 1.5315 | 🎯 Valid Accuracy: 67.7245\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [25/500] | 📉 Train Loss: 0.2103 | 🎯 Train Accuracy: 91.1781 | 📑 Valid Loss: 1.5025 | 🎯 Valid Accuracy: 68.5010\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [26/500] | 📉 Train Loss: 0.2031 | 🎯 Train Accuracy: 91.0928 | 📑 Valid Loss: 1.5292 | 🎯 Valid Accuracy: 67.9608\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [27/500] | 📉 Train Loss: 0.2046 | 🎯 Train Accuracy: 90.9220 | 📑 Valid Loss: 1.5557 | 🎯 Valid Accuracy: 67.8933\n",
      "현재 학습률: 0.000050\n",
      "🚀 Epoch [28/500] | 📉 Train Loss: 0.1993 | 🎯 Train Accuracy: 91.1117 | 📑 Valid Loss: 1.5607 | 🎯 Valid Accuracy: 68.7036\n",
      "현재 학습률: 0.000050\n",
      "🚨 조기 종료: 20 에폭 동안 개선 없음.\n",
      "🎯 최종 최고 검증 정확도: 69.51%\n",
      "✅ 학습 기록 저장 완료: C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\csv\\텐트분류3.csv\n",
      "🎯 테스트 데이터셋 정확도: 68.84%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Subset  # [변경됨]: random_split 대신 Subset 사용\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np  # [변경됨]: numpy 임포트\n",
    "\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 데이터 경로 설정\n",
    "data_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\data\\brand_data5\"\n",
    "processed_data_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\data\\processed_data5\"\n",
    "json_save_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\json\"\n",
    "csv_save_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\csv\"\n",
    "model_save_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet18-real\\modelnew\\resnet18-5.pth\"\n",
    "\n",
    "# JSON, CSV 저장 폴더 생성\n",
    "os.makedirs(json_save_dir, exist_ok=True)\n",
    "os.makedirs(csv_save_dir, exist_ok=True)\n",
    "\n",
    "# 모든 브랜드 폴더를 순회하면서 하위 제품 폴더 이동\n",
    "for brand in os.listdir(data_dir):\n",
    "    brand_path = os.path.join(data_dir, brand)\n",
    "    if os.path.isdir(brand_path):\n",
    "        for product in os.listdir(brand_path):\n",
    "            product_path = os.path.join(brand_path, product)\n",
    "            if os.path.isdir(product_path):\n",
    "                new_product_path = os.path.join(processed_data_dir, product)\n",
    "                os.makedirs(new_product_path, exist_ok=True)\n",
    "                for image in os.listdir(product_path):\n",
    "                    src = os.path.join(product_path, image)\n",
    "                    dst = os.path.join(new_product_path, image)\n",
    "                    shutil.copy(src, dst)\n",
    "\n",
    "print(\"✅ 모든 제품 폴더를 'processed_data5'로 이동 완료!\")\n",
    "\n",
    "# 이미지 변환 설정\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 데이터셋 로드\n",
    "dataset = datasets.ImageFolder(root=processed_data_dir, transform=transform)\n",
    "num_classes = len(dataset.classes)\n",
    "print(f\"총 클래스 개수: {num_classes}\")\n",
    "print(\"클래스 목록:\", dataset.classes)\n",
    "\n",
    "# [변경됨] 데이터셋 분할 - 클래스별로 7:2:1 비율로 분할\n",
    "# 각 클래스별 인덱스 추출\n",
    "class_indices = {cls: [] for cls in range(num_classes)}\n",
    "for idx, (path, label) in enumerate(dataset.imgs):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "train_indices, val_indices, test_indices = [], [], []\n",
    "for label, indices in class_indices.items():\n",
    "    np.random.shuffle(indices)  # 인덱스 랜덤 셔플\n",
    "    n = len(indices)\n",
    "    n_train = int(0.7 * n)\n",
    "    n_val = int(0.2 * n)\n",
    "    # 나머지는 테스트셋에 할당\n",
    "    train_indices.extend(indices[:n_train])\n",
    "    val_indices.extend(indices[n_train:n_train+n_val])\n",
    "    test_indices.extend(indices[n_train+n_val:])\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "# [변경됨 끝]\n",
    "\n",
    "# JSON 파일로 데이터셋 저장\n",
    "def save_json(subset_dataset, dataset_name):\n",
    "    data_list = [{\"image_path\": subset_dataset.dataset.imgs[i][0], \"label\": int(subset_dataset.dataset.imgs[i][1])} \n",
    "                for i in subset_dataset.indices]\n",
    "    json_path = os.path.join(json_save_dir, f\"{dataset_name}.json\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data_list, f, indent=4)\n",
    "    print(f\"✅ {dataset_name}.json 저장 완료!\")\n",
    "\n",
    "save_json(train_dataset, \"train5\")\n",
    "save_json(val_dataset, \"val5\")\n",
    "save_json(test_dataset, \"test5\")\n",
    "\n",
    "# 데이터 로더 설정\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"✅ 데이터 로더 생성 완료!\")\n",
    "\n",
    "# 모델 설정 (ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# 손실 함수 및 최적화 함수 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "\n",
    "# [추가됨] Learning rate scheduler (ReduceLROnPlateau 사용 - 검증 정확도를 기준으로 학습률 조절)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "# 학습 기록 저장용 DataFrame\n",
    "history = {\"epoch\": [], \"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "# [추가됨] Early Stopping 설정 변수 (개선이 없을 시 조기 종료)\n",
    "early_stop_patience = 20\n",
    "no_improve_count = 0\n",
    "\n",
    "# [추가됨] 로그 파일 생성 (학습 기록 추가 저장)\n",
    "log_file = os.path.join(csv_save_dir, \"train_log5.txt\")\n",
    "with open(log_file, \"w\") as lf:\n",
    "    lf.write(\"Epoch,Train Loss,Train Acc,Val Loss,Val Acc,Learning Rate\\n\")\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "    global no_improve_count  # [추가됨] early stopping 카운트 변수 사용\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_train += predicted.eq(labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct_val += predicted.eq(labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        history[\"epoch\"].append(epoch + 1)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"🚀 Epoch [{epoch+1}/{num_epochs}] | 📉 Train Loss: {train_loss:.4f} | 🎯 Train Accuracy: {train_acc:.4f} | 📑 Valid Loss: {val_loss:.4f} | 🎯 Valid Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # [추가됨] Learning rate scheduler step (검증 정확도를 기준으로 학습률 조정)\n",
    "        scheduler.step(val_acc)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"현재 학습률: {current_lr:.6f}\")\n",
    "\n",
    "        # [추가됨] 로그 파일에 학습 기록 추가 저장\n",
    "        with open(log_file, \"a\") as lf:\n",
    "            lf.write(f\"{epoch+1},{train_loss:.4f},{train_acc:.4f},{val_loss:.4f},{val_acc:.4f},{current_lr:.6f}\\n\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"📌 새로운 최고 모델 저장됨! (Epoch {epoch+1}, Accuracy: {val_acc:.4f}) ✅\")\n",
    "            no_improve_count = 0  # [추가됨] 개선되었으므로 카운트 초기화\n",
    "        else:\n",
    "            no_improve_count += 1  # [추가됨] 개선되지 않음\n",
    "\n",
    "        # [추가됨] Early Stopping 조건 확인 (개선이 없으면 조기 종료)\n",
    "        if no_improve_count >= early_stop_patience:\n",
    "            print(f\"🚨 조기 종료: {early_stop_patience} 에폭 동안 개선 없음.\")\n",
    "            break\n",
    "\n",
    "    print(f\"🎯 최종 최고 검증 정확도: {best_acc:.2f}%\")\n",
    "\n",
    "# 모델 학습 실행\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=500)\n",
    "\n",
    "# 학습 과정 CSV로 저장\n",
    "df = pd.DataFrame(history)\n",
    "csv_path = os.path.join(csv_save_dir, \"텐트분류3.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"✅ 학습 기록 저장 완료: {csv_path}\")\n",
    "\n",
    "# 최적 모델 로드 후 테스트 데이터 평가\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "correct_test, total_test = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_test += predicted.eq(labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "\n",
    "test_acc = 100 * correct_test / total_test\n",
    "print(f\"🎯 테스트 데이터셋 정확도: {test_acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
