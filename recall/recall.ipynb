{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ Train ì •í™•ë„: 4280/4281 (99.98%)\n",
      "ğŸ“Œ Val ì •í™•ë„: 1170/1229 (95.20%)\n",
      "ğŸ“Œ Test ì •í™•ë„: 574/606 (94.72%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from PIL import Image\n",
    "\n",
    "# âœ… ê²½ë¡œ ì„¤ì •\n",
    "model_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet182-real\\model\\model3newcopy2.pth\"\n",
    "json_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet182-real\\jsonnew\"\n",
    "\n",
    "train_json_path = os.path.join(json_dir, \"trainqwercopy2.json\")\n",
    "val_json_path = os.path.join(json_dir, \"valqwercopy2.json\")\n",
    "test_json_path = os.path.join(json_dir, \"testqwercopy2.json\")\n",
    "\n",
    "# âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì„¤ì •\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# âœ… JSON ë°ì´í„° ë¡œë“œ\n",
    "def load_json_data(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_json_data(train_json_path)\n",
    "val_data = load_json_data(val_json_path)\n",
    "test_data = load_json_data(test_json_path)\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# âœ… ë°ì´í„° ë¡œë” ìƒì„±\n",
    "batch_size = 32\n",
    "train_dataset = CustomDataset(train_data, transform)\n",
    "val_dataset = CustomDataset(val_data, transform)\n",
    "test_dataset = CustomDataset(test_data, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# âœ… ëª¨ë¸ ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ì ìš©\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = efficientnet_b0(weights=None)  # ê¸°ì¡´ ëª¨ë¸ êµ¬ì¡°\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(set([item[1] for item in train_data])))  # í´ë˜ìŠ¤ ê°œìˆ˜ ì¡°ì •\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# âœ… ì •í™•ë„ í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return correct, total, accuracy\n",
    "\n",
    "# âœ… ê° ë°ì´í„°ì…‹ë³„ í‰ê°€ ì‹¤í–‰\n",
    "train_correct, train_total, train_acc = evaluate(model, train_loader)\n",
    "val_correct, val_total, val_acc = evaluate(model, val_loader)\n",
    "test_correct, test_total, test_acc = evaluate(model, test_loader)\n",
    "\n",
    "# âœ… ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ğŸ“Œ Train ì •í™•ë„: {train_correct}/{train_total} ({train_acc * 100:.2f}%)\")\n",
    "print(f\"ğŸ“Œ Val ì •í™•ë„: {val_correct}/{val_total} ({val_acc * 100:.2f}%)\")\n",
    "print(f\"ğŸ“Œ Test ì •í™•ë„: {test_correct}/{test_total} ({test_acc * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: Train(4767), Val(1368), Test(675)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Train ë°ì´í„°ì…‹ ì˜¤ë¥˜ ì´ë¯¸ì§€ ì €ì¥: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [01:00<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train: ì´ 0ê°œì˜ í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Validation ë°ì´í„°ì…‹ ì˜¤ë¥˜ ì´ë¯¸ì§€ ì €ì¥: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43/43 [00:17<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Validation: ì´ 86ê°œì˜ í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Test ë°ì´í„°ì…‹ ì˜¤ë¥˜ ì´ë¯¸ì§€ ì €ì¥: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:08<00:00,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test: ì´ 38ê°œì˜ í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn  # âœ… ì˜¤ë¥˜ í•´ê²°: torch.nn ì¶”ê°€\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "from PIL import Image\n",
    "\n",
    "# âœ… ê²½ë¡œ ì„¤ì •\n",
    "json_dir = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet182-real\\jsonnew\"\n",
    "recall_root = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet182-real\\recall\"\n",
    "misclassified_root = os.path.join(recall_root, \"misclassified_data\")\n",
    "original_dataset_root = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet182-real\\data\\category_data3\"\n",
    "\n",
    "# âœ… JSON ë°ì´í„° ë¡œë“œ\n",
    "def load_json_data(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_json_data(os.path.join(json_dir, \"trainqwer.json\"))\n",
    "val_data = load_json_data(os.path.join(json_dir, \"valqwer.json\"))\n",
    "test_data = load_json_data(os.path.join(json_dir, \"testqwer.json\"))\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: Train({len(train_data)}), Val({len(val_data)}), Test({len(test_data)})\")\n",
    "\n",
    "# âœ… ë°ì´í„° ë³€í™˜ ì„¤ì •\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# âœ… ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (íŒŒì¼ ê²½ë¡œ í¬í•¨)\n",
    "class CustomDatasetWithPaths(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, img_path\n",
    "\n",
    "# âœ… ë°ì´í„°ë¡œë” ìƒì„±\n",
    "batch_size = 32\n",
    "train_loader_paths = DataLoader(CustomDatasetWithPaths(train_data, transform), batch_size=batch_size, shuffle=False)\n",
    "val_loader_paths = DataLoader(CustomDatasetWithPaths(val_data, transform), batch_size=batch_size, shuffle=False)\n",
    "test_loader_paths = DataLoader(CustomDatasetWithPaths(test_data, transform), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# âœ… ëª¨ë¸ ë¡œë“œ ë° í‰ê°€ í•¨ìˆ˜\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = r\"C:\\Users\\user\\OneDrive\\Desktop\\Resnet182-real\\model\\model3new.pth\"\n",
    "model = efficientnet_b0(weights=None)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(set([item[1] for item in train_data])))  # âœ… ì˜¤ë¥˜ í•´ê²°\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# âœ… í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥ í•¨ìˆ˜\n",
    "def save_misclassified_images(model, dataloader, dataset_name):\n",
    "    model.eval()\n",
    "    misclassified_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths in tqdm(dataloader, desc=f\"ğŸ” {dataset_name} ë°ì´í„°ì…‹ ì˜¤ë¥˜ ì´ë¯¸ì§€ ì €ì¥\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            for img_path, pred, label in zip(paths, predicted.cpu().numpy(), labels.cpu().numpy()):\n",
    "                if pred != label:\n",
    "                    # âœ… ì›ë³¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìœ ì§€í•˜ì—¬ ì €ì¥\n",
    "                    relative_path = os.path.relpath(img_path, original_dataset_root)\n",
    "                    save_path = os.path.join(misclassified_root, relative_path)\n",
    "\n",
    "                    # âœ… í´ë” ìƒì„± í›„ ì´ë¯¸ì§€ ë³µì‚¬\n",
    "                    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                    shutil.copy(img_path, save_path)\n",
    "                    misclassified_count += 1\n",
    "\n",
    "    print(f\"âœ… {dataset_name}: ì´ {misclassified_count}ê°œì˜ í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "# âœ… í‹€ë¦° ì´ë¯¸ì§€ ì €ì¥ ì‹¤í–‰\n",
    "save_misclassified_images(model, train_loader_paths, \"Train\")\n",
    "save_misclassified_images(model, val_loader_paths, \"Validation\")\n",
    "save_misclassified_images(model, test_loader_paths, \"Test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
